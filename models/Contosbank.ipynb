{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip show azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: azure-ai-ml\r\nVersion: 1.20.0\r\nSummary: Microsoft Azure Machine Learning Client Library for Python\r\nHome-page: https://github.com/Azure/azure-sdk-for-python\r\nAuthor: Microsoft Corporation\r\nAuthor-email: azuresdkengsysadmins@microsoft.com\r\nLicense: MIT License\r\nLocation: /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages\r\nRequires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, opencensus-ext-logging, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\r\nRequired-by: \r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1728491939025
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728491942564
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728491948842
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))\n",
        "print(ws.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.57.0 to work with mlw-cb-lf66db13b49ae47f691\nmlw-cb-lf66db13b49ae47f691\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728491784445
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "list data datastore"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stores = ml_client.datastores.list()\n",
        "for ds_name in stores:\n",
        "    print(ds_name.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "blob_training_data\nworkspaceblobstore\nworkspaceartifactstore\nworkspaceworkingdirectory\nworkspacefilestore\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728490125813
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a datastore"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AzureBlobDatastore\n",
        "from azure.ai.ml.entities import AccountKeyConfiguration\n",
        "\n",
        "store = AzureBlobDatastore(\n",
        "    name=\"blob_training_data\",\n",
        "    description=\"Blob Storage for training data\",\n",
        "    account_name=\"mlwcblf6storagea12fca3b2\",\n",
        "    container_name=\"training-data\", \n",
        "    credentials=AccountKeyConfiguration(\n",
        "        account_key=\"GmmXUXH+v8EpX5D9y+ORBwBl8DftM6de9EdfWQt3AKombbK3IgvA5aM37uq31XmiDn7ezBrAV9ry+ASt3GPOfg==\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "ml_client.create_or_update(store)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "create dataset1"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "my_path = './Data/Dataset1.csv'\n",
        "\n",
        "my_data = Data(\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\n",
        "    name=\"Dataset11\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "Data({'path': 'azureml://subscriptions/805e2807-b34c-423a-83fb-6c6c635d5b7a/resourcegroups/rg-contosobank-lf66db13b49ae47f691/workspaces/mlw-cb-lf66db13b49ae47f691/datastores/workspaceblobstore/paths/LocalUpload/e7cf903974719366f66e285518e48dfd/Dataset1.csv', 'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'Dataset11', 'description': 'Data asset pointing to a local file, automatically uploaded to the default datastore', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/805e2807-b34c-423a-83fb-6c6c635d5b7a/resourceGroups/rg-contosobank-lf66db13b49ae47f691/providers/Microsoft.MachineLearningServices/workspaces/mlw-cb-lf66db13b49ae47f691/data/Dataset11/versions/1', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cb-cif66db13b49ae47f691/code/Users/aoaitfs9067/cbsb/models', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f70d3b1ea10>, 'serialize': <msrest.serialization.Serializer object at 0x7f70d3b1dd80>, 'version': '1', 'latest_version': None, 'datastore': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728492040751
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import dataset 2 to defauLT DATASTORE"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "my_path = './Data/Dataset2.csv'\n",
        "\n",
        "my_data = Data(\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\n",
        "    name=\"Dataset22\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "Data({'path': 'azureml://subscriptions/805e2807-b34c-423a-83fb-6c6c635d5b7a/resourcegroups/rg-contosobank-lf66db13b49ae47f691/workspaces/mlw-cb-lf66db13b49ae47f691/datastores/workspaceblobstore/paths/LocalUpload/b72fc6488ebfdadc2441905afe30b573/Dataset2.csv', 'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'Dataset22', 'description': 'Data asset pointing to a local file, automatically uploaded to the default datastore', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/805e2807-b34c-423a-83fb-6c6c635d5b7a/resourceGroups/rg-contosobank-lf66db13b49ae47f691/providers/Microsoft.MachineLearningServices/workspaces/mlw-cb-lf66db13b49ae47f691/data/Dataset22/versions/1', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cb-cif66db13b49ae47f691/code/Users/aoaitfs9067/cbsb/models', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f70d21a5330>, 'serialize': <msrest.serialization.Serializer object at 0x7f70d21a5d80>, 'version': '1', 'latest_version': None, 'datastore': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728492054181
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import and merge data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from azureml.core import Workspace, Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the workspace\n",
        "ws = Workspace.from_config()  # Ensure config.json is in the current directory\n",
        "\n",
        "# Step 2: Get the datasets by name\n",
        "part1 = Dataset.get_by_name(workspace=ws, name='Data1set1')\n",
        "part2 = Dataset.get_by_name(workspace=ws, name='Data1set2')\n",
        "\n",
        "# Step 3: Convert the datasets to pandas dataframes\n",
        "df_part1 = part1.to_pandas_dataframe()\n",
        "df_part2 = part2.to_pandas_dataframe()\n",
        "\n",
        "# Step 4: Remove duplicates from both datasets\n",
        "df_part1_nodups = df_part1.drop_duplicates()\n",
        "df_part2_nodups = df_part2.drop_duplicates()\n",
        "\n",
        "# Step 5: Merge the two datasets on a common column ('ID')\n",
        "merged_data = pd.merge(left=df_part1_nodups, right=df_part2_nodups, on='ID')\n",
        "\n",
        "# Step 6: Save the merged dataframe to a CSV file (if needed)\n",
        "merged_data.to_csv('merged_data.csv', index=False)\n",
        "\n",
        "print(\"Datasets have been successfully cleaned, merged, and saved as 'merged_data.csv'.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe'}\n{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe', 'activityApp': 'TabularDataset'}\n{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe'}\n{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe', 'activityApp': 'TabularDataset'}\nDatasets have been successfully cleaned, merged, and saved as 'merged_data.csv'.\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728492228139
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#preview original dataset1.\n",
        "merged_data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "   ID  Age  CustomerSince  HighestSpend  ZipCode  HiddenScore  \\\n0   1   25              1            49    91107            4   \n1   2   45             19            34    90089            3   \n2   3   39             15            11    94720            1   \n3   4   35              9           100    94112            1   \n4   5   35              8            45    91330            4   \n\n   MonthlyAverageSpend  Level  Mortgage  Security  FixedDepositAccount  \\\n0                  1.6      1         0         1                    0   \n1                  1.5      1         0         1                    0   \n2                  1.0      1         0         0                    0   \n3                  2.7      2         0         0                    0   \n4                  1.0      2         0         0                    0   \n\n   InternetBanking  CreditCard  LoanOnCard  \n0                0           0         NaN  \n1                0           0         NaN  \n2                0           0         NaN  \n3                0           0         NaN  \n4                0           1         NaN  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Age</th>\n      <th>CustomerSince</th>\n      <th>HighestSpend</th>\n      <th>ZipCode</th>\n      <th>HiddenScore</th>\n      <th>MonthlyAverageSpend</th>\n      <th>Level</th>\n      <th>Mortgage</th>\n      <th>Security</th>\n      <th>FixedDepositAccount</th>\n      <th>InternetBanking</th>\n      <th>CreditCard</th>\n      <th>LoanOnCard</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>25</td>\n      <td>1</td>\n      <td>49</td>\n      <td>91107</td>\n      <td>4</td>\n      <td>1.6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>45</td>\n      <td>19</td>\n      <td>34</td>\n      <td>90089</td>\n      <td>3</td>\n      <td>1.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>39</td>\n      <td>15</td>\n      <td>11</td>\n      <td>94720</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>35</td>\n      <td>9</td>\n      <td>100</td>\n      <td>94112</td>\n      <td>1</td>\n      <td>2.7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>35</td>\n      <td>8</td>\n      <td>45</td>\n      <td>91330</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728492290283
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_part1.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "   ID  Age  CustomerSince  HighestSpend  ZipCode  HiddenScore  \\\n0   1   25              1            49    91107            4   \n1   2   45             19            34    90089            3   \n2   3   39             15            11    94720            1   \n3   4   35              9           100    94112            1   \n4   5   35              8            45    91330            4   \n\n   MonthlyAverageSpend  Level  \n0                  1.6      1  \n1                  1.5      1  \n2                  1.0      1  \n3                  2.7      2  \n4                  1.0      2  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Age</th>\n      <th>CustomerSince</th>\n      <th>HighestSpend</th>\n      <th>ZipCode</th>\n      <th>HiddenScore</th>\n      <th>MonthlyAverageSpend</th>\n      <th>Level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>25</td>\n      <td>1</td>\n      <td>49</td>\n      <td>91107</td>\n      <td>4</td>\n      <td>1.6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>45</td>\n      <td>19</td>\n      <td>34</td>\n      <td>90089</td>\n      <td>3</td>\n      <td>1.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>39</td>\n      <td>15</td>\n      <td>11</td>\n      <td>94720</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>35</td>\n      <td>9</td>\n      <td>100</td>\n      <td>94112</td>\n      <td>1</td>\n      <td>2.7</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>35</td>\n      <td>8</td>\n      <td>45</td>\n      <td>91330</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728492369764
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_part2.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "   ID  Mortgage  Security  FixedDepositAccount  InternetBanking  CreditCard  \\\n0   1         0         1                    0                0           0   \n1   2         0         1                    0                0           0   \n2   3         0         0                    0                0           0   \n3   4         0         0                    0                0           0   \n4   5         0         0                    0                0           1   \n\n   LoanOnCard  \n0         NaN  \n1         NaN  \n2         NaN  \n3         NaN  \n4         NaN  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Mortgage</th>\n      <th>Security</th>\n      <th>FixedDepositAccount</th>\n      <th>InternetBanking</th>\n      <th>CreditCard</th>\n      <th>LoanOnCard</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728492382219
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preview your Data\n",
        "merged_data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "   ID  Age  CustomerSince  HighestSpend  ZipCode  HiddenScore  \\\n0   1   25              1            49    91107            4   \n1   2   45             19            34    90089            3   \n2   3   39             15            11    94720            1   \n3   4   35              9           100    94112            1   \n4   5   35              8            45    91330            4   \n\n   MonthlyAverageSpend  Level  Mortgage  Security  FixedDepositAccount  \\\n0                  1.6      1         0         1                    0   \n1                  1.5      1         0         1                    0   \n2                  1.0      1         0         0                    0   \n3                  2.7      2         0         0                    0   \n4                  1.0      2         0         0                    0   \n\n   InternetBanking  CreditCard  LoanOnCard  \n0                0           0         NaN  \n1                0           0         NaN  \n2                0           0         NaN  \n3                0           0         NaN  \n4                0           1         NaN  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Age</th>\n      <th>CustomerSince</th>\n      <th>HighestSpend</th>\n      <th>ZipCode</th>\n      <th>HiddenScore</th>\n      <th>MonthlyAverageSpend</th>\n      <th>Level</th>\n      <th>Mortgage</th>\n      <th>Security</th>\n      <th>FixedDepositAccount</th>\n      <th>InternetBanking</th>\n      <th>CreditCard</th>\n      <th>LoanOnCard</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>25</td>\n      <td>1</td>\n      <td>49</td>\n      <td>91107</td>\n      <td>4</td>\n      <td>1.6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>45</td>\n      <td>19</td>\n      <td>34</td>\n      <td>90089</td>\n      <td>3</td>\n      <td>1.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>39</td>\n      <td>15</td>\n      <td>11</td>\n      <td>94720</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>35</td>\n      <td>9</td>\n      <td>100</td>\n      <td>94112</td>\n      <td>1</td>\n      <td>2.7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>35</td>\n      <td>8</td>\n      <td>45</td>\n      <td>91330</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728492330594
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Describe the data after transposing. \n",
        "merged_data.describe().transpose()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "                      count          mean          std     min       25%  \\\nID                   5000.0   2500.500000  1443.520003     1.0   1250.75   \nAge                  5000.0     45.338400    11.463166    23.0     35.00   \nCustomerSince        5000.0     20.104600    11.467954    -3.0     10.00   \nHighestSpend         5000.0     73.774200    46.033729     8.0     39.00   \nZipCode              5000.0  93152.503000  2121.852197  9307.0  91911.00   \nHiddenScore          5000.0      2.396400     1.147663     1.0      1.00   \nMonthlyAverageSpend  5000.0      1.937938     1.747659     0.0      0.70   \nLevel                5000.0      1.881000     0.839869     1.0      1.00   \nMortgage             5000.0     56.498800   101.713802     0.0      0.00   \nSecurity             5000.0      0.104400     0.305809     0.0      0.00   \nFixedDepositAccount  5000.0      0.060400     0.238250     0.0      0.00   \nInternetBanking      5000.0      0.596800     0.490589     0.0      0.00   \nCreditCard           5000.0      0.294000     0.455637     0.0      0.00   \nLoanOnCard           4980.0      0.096386     0.295149     0.0      0.00   \n\n                         50%       75%      max  \nID                    2500.5   3750.25   5000.0  \nAge                     45.0     55.00     67.0  \nCustomerSince           20.0     30.00     43.0  \nHighestSpend            64.0     98.00    224.0  \nZipCode              93437.0  94608.00  96651.0  \nHiddenScore              2.0      3.00      4.0  \nMonthlyAverageSpend      1.5      2.50     10.0  \nLevel                    2.0      3.00      3.0  \nMortgage                 0.0    101.00    635.0  \nSecurity                 0.0      0.00      1.0  \nFixedDepositAccount      0.0      0.00      1.0  \nInternetBanking          1.0      1.00      1.0  \nCreditCard               0.0      1.00      1.0  \nLoanOnCard               0.0      0.00      1.0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ID</th>\n      <td>5000.0</td>\n      <td>2500.500000</td>\n      <td>1443.520003</td>\n      <td>1.0</td>\n      <td>1250.75</td>\n      <td>2500.5</td>\n      <td>3750.25</td>\n      <td>5000.0</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>5000.0</td>\n      <td>45.338400</td>\n      <td>11.463166</td>\n      <td>23.0</td>\n      <td>35.00</td>\n      <td>45.0</td>\n      <td>55.00</td>\n      <td>67.0</td>\n    </tr>\n    <tr>\n      <th>CustomerSince</th>\n      <td>5000.0</td>\n      <td>20.104600</td>\n      <td>11.467954</td>\n      <td>-3.0</td>\n      <td>10.00</td>\n      <td>20.0</td>\n      <td>30.00</td>\n      <td>43.0</td>\n    </tr>\n    <tr>\n      <th>HighestSpend</th>\n      <td>5000.0</td>\n      <td>73.774200</td>\n      <td>46.033729</td>\n      <td>8.0</td>\n      <td>39.00</td>\n      <td>64.0</td>\n      <td>98.00</td>\n      <td>224.0</td>\n    </tr>\n    <tr>\n      <th>ZipCode</th>\n      <td>5000.0</td>\n      <td>93152.503000</td>\n      <td>2121.852197</td>\n      <td>9307.0</td>\n      <td>91911.00</td>\n      <td>93437.0</td>\n      <td>94608.00</td>\n      <td>96651.0</td>\n    </tr>\n    <tr>\n      <th>HiddenScore</th>\n      <td>5000.0</td>\n      <td>2.396400</td>\n      <td>1.147663</td>\n      <td>1.0</td>\n      <td>1.00</td>\n      <td>2.0</td>\n      <td>3.00</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>MonthlyAverageSpend</th>\n      <td>5000.0</td>\n      <td>1.937938</td>\n      <td>1.747659</td>\n      <td>0.0</td>\n      <td>0.70</td>\n      <td>1.5</td>\n      <td>2.50</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>Level</th>\n      <td>5000.0</td>\n      <td>1.881000</td>\n      <td>0.839869</td>\n      <td>1.0</td>\n      <td>1.00</td>\n      <td>2.0</td>\n      <td>3.00</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>Mortgage</th>\n      <td>5000.0</td>\n      <td>56.498800</td>\n      <td>101.713802</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>101.00</td>\n      <td>635.0</td>\n    </tr>\n    <tr>\n      <th>Security</th>\n      <td>5000.0</td>\n      <td>0.104400</td>\n      <td>0.305809</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>FixedDepositAccount</th>\n      <td>5000.0</td>\n      <td>0.060400</td>\n      <td>0.238250</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>InternetBanking</th>\n      <td>5000.0</td>\n      <td>0.596800</td>\n      <td>0.490589</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>1.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>CreditCard</th>\n      <td>5000.0</td>\n      <td>0.294000</td>\n      <td>0.455637</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>LoanOnCard</th>\n      <td>4980.0</td>\n      <td>0.096386</td>\n      <td>0.295149</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728492463758
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# every column's missing value is replaced with 0 respectively . In this case LoanOnCard which is our target/outcome variable\n",
        "merged_data = merged_data.dropna(axis=0)\n",
        "merged_data"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "        ID  Age  CustomerSince  HighestSpend  ZipCode  HiddenScore  \\\n9       10   34              9           180    93023            1   \n10      11   65             39           105    94710            4   \n11      12   29              5            45    90277            3   \n12      13   48             23           114    93106            2   \n13      14   59             32            40    94920            4   \n...    ...  ...            ...           ...      ...          ...   \n4995  4996   29              3            40    92697            1   \n4996  4997   30              4            15    92037            4   \n4997  4998   63             39            24    93023            2   \n4998  4999   65             40            49    90034            3   \n4999  5000   28              4            83    92612            3   \n\n      MonthlyAverageSpend  Level  Mortgage  Security  FixedDepositAccount  \\\n9                     8.9      3         0         0                    0   \n10                    2.4      3         0         0                    0   \n11                    0.1      2         0         0                    0   \n12                    3.8      3         0         1                    0   \n13                    2.5      2         0         0                    0   \n...                   ...    ...       ...       ...                  ...   \n4995                  1.9      3         0         0                    0   \n4996                  0.4      1        85         0                    0   \n4997                  0.3      3         0         0                    0   \n4998                  0.5      2         0         0                    0   \n4999                  0.8      1         0         0                    0   \n\n      InternetBanking  CreditCard  LoanOnCard  \n9                   0           0         1.0  \n10                  0           0         0.0  \n11                  1           0         0.0  \n12                  0           0         0.0  \n13                  1           0         0.0  \n...               ...         ...         ...  \n4995                1           0         0.0  \n4996                1           0         0.0  \n4997                0           0         0.0  \n4998                1           0         0.0  \n4999                1           1         0.0  \n\n[4980 rows x 14 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Age</th>\n      <th>CustomerSince</th>\n      <th>HighestSpend</th>\n      <th>ZipCode</th>\n      <th>HiddenScore</th>\n      <th>MonthlyAverageSpend</th>\n      <th>Level</th>\n      <th>Mortgage</th>\n      <th>Security</th>\n      <th>FixedDepositAccount</th>\n      <th>InternetBanking</th>\n      <th>CreditCard</th>\n      <th>LoanOnCard</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>34</td>\n      <td>9</td>\n      <td>180</td>\n      <td>93023</td>\n      <td>1</td>\n      <td>8.9</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>65</td>\n      <td>39</td>\n      <td>105</td>\n      <td>94710</td>\n      <td>4</td>\n      <td>2.4</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>29</td>\n      <td>5</td>\n      <td>45</td>\n      <td>90277</td>\n      <td>3</td>\n      <td>0.1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>48</td>\n      <td>23</td>\n      <td>114</td>\n      <td>93106</td>\n      <td>2</td>\n      <td>3.8</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>59</td>\n      <td>32</td>\n      <td>40</td>\n      <td>94920</td>\n      <td>4</td>\n      <td>2.5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>4996</td>\n      <td>29</td>\n      <td>3</td>\n      <td>40</td>\n      <td>92697</td>\n      <td>1</td>\n      <td>1.9</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>4997</td>\n      <td>30</td>\n      <td>4</td>\n      <td>15</td>\n      <td>92037</td>\n      <td>4</td>\n      <td>0.4</td>\n      <td>1</td>\n      <td>85</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>4998</td>\n      <td>63</td>\n      <td>39</td>\n      <td>24</td>\n      <td>93023</td>\n      <td>2</td>\n      <td>0.3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>4999</td>\n      <td>65</td>\n      <td>40</td>\n      <td>49</td>\n      <td>90034</td>\n      <td>3</td>\n      <td>0.5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>5000</td>\n      <td>28</td>\n      <td>4</td>\n      <td>83</td>\n      <td>92612</td>\n      <td>3</td>\n      <td>0.8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4980 rows × 14 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728492521248
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for non numeric value in the dataframe, again.\n",
        "merged_data.isna().sum()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "ID                     0\nAge                    0\nCustomerSince          0\nHighestSpend           0\nZipCode                0\nHiddenScore            0\nMonthlyAverageSpend    0\nLevel                  0\nMortgage               0\nSecurity               0\nFixedDepositAccount    0\nInternetBanking        0\nCreditCard             0\nLoanOnCard             0\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728492556598
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Customer ID attribute 'ID' does not influence the conversion to potential customers for loanoncard \n",
        "# so dropping the 'ID' attribute\n",
        "# Assuming that the 'Zipcode' (in other words 'area') of the customers does not influence the \n",
        "# conversion to potential customers for loanoncard. So dropping the 'Zipcode' attribute\n",
        "merged_data = merged_data.drop('ID', axis =1 ) \n",
        "merged_data = merged_data.drop('ZipCode', axis =1 )"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728492612209
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the data now. \n",
        "merged_data"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "      Age  CustomerSince  HighestSpend  HiddenScore  MonthlyAverageSpend  \\\n9      34              9           180            1                  8.9   \n10     65             39           105            4                  2.4   \n11     29              5            45            3                  0.1   \n12     48             23           114            2                  3.8   \n13     59             32            40            4                  2.5   \n...   ...            ...           ...          ...                  ...   \n4995   29              3            40            1                  1.9   \n4996   30              4            15            4                  0.4   \n4997   63             39            24            2                  0.3   \n4998   65             40            49            3                  0.5   \n4999   28              4            83            3                  0.8   \n\n      Level  Mortgage  Security  FixedDepositAccount  InternetBanking  \\\n9         3         0         0                    0                0   \n10        3         0         0                    0                0   \n11        2         0         0                    0                1   \n12        3         0         1                    0                0   \n13        2         0         0                    0                1   \n...     ...       ...       ...                  ...              ...   \n4995      3         0         0                    0                1   \n4996      1        85         0                    0                1   \n4997      3         0         0                    0                0   \n4998      2         0         0                    0                1   \n4999      1         0         0                    0                1   \n\n      CreditCard  LoanOnCard  \n9              0         1.0  \n10             0         0.0  \n11             0         0.0  \n12             0         0.0  \n13             0         0.0  \n...          ...         ...  \n4995           0         0.0  \n4996           0         0.0  \n4997           0         0.0  \n4998           0         0.0  \n4999           1         0.0  \n\n[4980 rows x 12 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>CustomerSince</th>\n      <th>HighestSpend</th>\n      <th>HiddenScore</th>\n      <th>MonthlyAverageSpend</th>\n      <th>Level</th>\n      <th>Mortgage</th>\n      <th>Security</th>\n      <th>FixedDepositAccount</th>\n      <th>InternetBanking</th>\n      <th>CreditCard</th>\n      <th>LoanOnCard</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>34</td>\n      <td>9</td>\n      <td>180</td>\n      <td>1</td>\n      <td>8.9</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>65</td>\n      <td>39</td>\n      <td>105</td>\n      <td>4</td>\n      <td>2.4</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>29</td>\n      <td>5</td>\n      <td>45</td>\n      <td>3</td>\n      <td>0.1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>48</td>\n      <td>23</td>\n      <td>114</td>\n      <td>2</td>\n      <td>3.8</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>59</td>\n      <td>32</td>\n      <td>40</td>\n      <td>4</td>\n      <td>2.5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>29</td>\n      <td>3</td>\n      <td>40</td>\n      <td>1</td>\n      <td>1.9</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>30</td>\n      <td>4</td>\n      <td>15</td>\n      <td>4</td>\n      <td>0.4</td>\n      <td>1</td>\n      <td>85</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>63</td>\n      <td>39</td>\n      <td>24</td>\n      <td>2</td>\n      <td>0.3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>65</td>\n      <td>40</td>\n      <td>49</td>\n      <td>3</td>\n      <td>0.5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>28</td>\n      <td>4</td>\n      <td>83</td>\n      <td>3</td>\n      <td>0.8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4980 rows × 12 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728492628723
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing For Modelling\n",
        "Treating Imbalanced Data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from azureml.core import Workspace, Dataset\n",
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "\n",
        "\n",
        "\n",
        "# Step 3: Separate majority and minority classes based on the 'LoanOnCard' column\n",
        "df_loan = merged_data[merged_data['LoanOnCard'] == 1]  # Minority class\n",
        "df_noloan = merged_data[merged_data['LoanOnCard'] == 0]  # Majority class\n",
        "\n",
        "# Step 4: Upsample the minority class (LoanOnCard == 1)\n",
        "df_loan_upsampled = resample(df_loan, replace=True, n_samples=4500, random_state=11)\n",
        "\n",
        "# Step 5: Combine the majority class (LoanOnCard == 0) with the upsampled minority class\n",
        "df_upsampled = pd.concat([df_noloan, df_loan_upsampled])\n",
        "\n",
        "# Step 6: Display new class counts\n",
        "class_counts = df_upsampled['LoanOnCard'].value_counts()\n",
        "print(\"New class distribution after upsampling:\")\n",
        "print(class_counts)\n",
        "\n",
        "# Step 7: Save the upsampled dataset to a CSV file\n",
        "df_upsampled.to_csv('upsampled_data.csv', index=False)\n",
        "print(\"Upsampled dataset saved as 'upsampled_data.csv'.\")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "New class distribution after upsampling:\nLoanOnCard\n0.0    4500\n1.0    4500\nName: count, dtype: int64\nUpsampled dataset saved as 'upsampled_data.csv'.\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728493481756
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_upsampled.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nIndex: 9000 entries, 10 to 2707\nData columns (total 12 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   Age                  9000 non-null   int64  \n 1   CustomerSince        9000 non-null   int64  \n 2   HighestSpend         9000 non-null   int64  \n 3   HiddenScore          9000 non-null   int64  \n 4   MonthlyAverageSpend  9000 non-null   float64\n 5   Level                9000 non-null   int64  \n 6   Mortgage             9000 non-null   int64  \n 7   Security             9000 non-null   int64  \n 8   FixedDepositAccount  9000 non-null   int64  \n 9   InternetBanking      9000 non-null   int64  \n 10  CreditCard           9000 non-null   int64  \n 11  LoanOnCard           9000 non-null   float64\ndtypes: float64(2), int64(10)\nmemory usage: 914.1 KB\n"
        }
      ],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728493556861
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from azureml.core import Workspace, Dataset\n",
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Step 4: Upsample the minority class (LoanOnCard == 1) with 70% of the majority class size (e.g., 3500 samples)\n",
        "df_loan_upsampled_70 = resample(df_loan, replace=True, n_samples=3500, random_state=13)\n",
        "\n",
        "# Step 5: Combine the majority class (LoanOnCard == 0) with the upsampled minority class\n",
        "df_upsampled_70 = pd.concat([df_noloan, df_loan_upsampled_70])\n",
        "\n",
        "# Step 6: Display new class counts after upsampling\n",
        "class_counts_70 = df_upsampled_70['LoanOnCard'].value_counts()\n",
        "print(\"New class distribution after 70% upsampling:\")\n",
        "print(class_counts_70)\n",
        "\n",
        "# Step 7: Save the 70% upsampled dataset to a CSV file\n",
        "df_upsampled_70.to_csv('upsampled_data_70.csv', index=False)\n",
        "print(\"70% upsampled dataset saved as 'upsampled_data_70.csv'.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "New class distribution after 70% upsampling:\nLoanOnCard\n0.0    4500\n1.0    3500\nName: count, dtype: int64\n70% upsampled dataset saved as 'upsampled_data_70.csv'.\n"
        }
      ],
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728493795669
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_upsampled_70.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nIndex: 8000 entries, 10 to 3006\nData columns (total 12 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   Age                  8000 non-null   int64  \n 1   CustomerSince        8000 non-null   int64  \n 2   HighestSpend         8000 non-null   int64  \n 3   HiddenScore          8000 non-null   int64  \n 4   MonthlyAverageSpend  8000 non-null   float64\n 5   Level                8000 non-null   int64  \n 6   Mortgage             8000 non-null   int64  \n 7   Security             8000 non-null   int64  \n 8   FixedDepositAccount  8000 non-null   int64  \n 9   InternetBanking      8000 non-null   int64  \n 10  CreditCard           8000 non-null   int64  \n 11  LoanOnCard           8000 non-null   float64\ndtypes: float64(2), int64(10)\nmemory usage: 812.5 KB\n"
        }
      ],
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728493836558
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Preparation\n",
        "### Split Data set into Train and Test data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Split the dataset into features (X) and target (y)\n",
        "X = merged_data.drop(['LoanOnCard'], axis=1)  # Drop the target column to get the features\n",
        "y = merged_data['LoanOnCard']  # Target column (label)"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728494111574
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_full = df_upsampled.drop(['LoanOnCard'],axis=1)\n",
        "y_full = df_upsampled.LoanOnCard\n",
        "X_70 = df_upsampled_70.drop(['LoanOnCard'],axis=1)\n",
        "y_70 = df_upsampled_70.LoanOnCard"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728494161241
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from azureml.core import Workspace, Dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 4: Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "\n",
        "# Step 5: Print the shapes of the training and testing sets\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "X_train shape: (3984, 11)\nX_test shape: (996, 11)\ny_train shape: (3984,)\ny_test shape: (996,)\n"
        }
      ],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728494429161
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train and test data (target fully sampled) at 80:20 ratio\n",
        "X_full_train, X_full_test, y_full_train, y_full_test = train_test_split(X_full, y_full, test_size=0.20, random_state=1)\n",
        "print(X_full_train.shape)\n",
        "print(X_full_test.shape)\n",
        "print(y_full_train.shape)\n",
        "print(y_full_test.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(7200, 11)\n(1800, 11)\n(7200,)\n(1800,)\n"
        }
      ],
      "execution_count": 46,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728494464131
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train and test data at 80:20 ratio\n",
        "X_70_train, X_70_test, y_70_train, y_70_test = train_test_split(X_70, y_70, test_size=0.20, random_state=1)\n",
        "print(X_70_train.shape)\n",
        "print(X_70_test.shape)\n",
        "print(y_70_train.shape)\n",
        "print(y_70_test.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(6400, 11)\n(1600, 11)\n(6400,)\n(1600,)\n"
        }
      ],
      "execution_count": 47,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728494482142
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelling Inferences\n",
        "After comparing various modelling techniques and with different kinds of tuning models and target data set, it is found that the Logistic Regression model with liblinear solver and with over-sampling of target minority class equal to that of the target majority class is the best model with better Recall, precision, f1-score and Accuracy score.\n",
        "\n",
        "Model Accuracy - 89%\n",
        "\n",
        "Class Precision - 90% (class 0), 88% (class 1)\n",
        "\n",
        "Class recall - 90% (class 0), 87% (class 1)\n",
        "\n",
        "Class f1-score - 90% (class 0), 87% (class 1)\n",
        "\n",
        "Based on our conculsion we are going to use the df_upsampled data. the reference to which can be found in the Treating the imbalanced data section above."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply Logistic Regression\n",
        "Configure automated machine learning job\n",
        "Now, you're ready to configure the automated machine learning experiment.\n",
        "\n",
        "When you run the code below, it will create an automated machine learning job that:\n",
        "\n",
        "Uses the compute cluster named \n",
        "Sets loan as the target column\n",
        "Sets accuracy as the primary metric\n",
        "Times out after 60 minutes of total training time\n",
        "Trains a maximum of 5 models\n",
        "No model will be trained with the LogisticRegression algorithm"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "local_path = 'Data/finance.csv'\n",
        "df_upsampled.to_csv(local_path)\n",
        "\n",
        "\n",
        "\n",
        "# get the datastore to upload prepared data\n",
        "datastore = ws.get_default_datastore()\n",
        "\n",
        "# upload the local file from src_dir to the target_path in datastore\n",
        "datastore.upload(src_dir='Data', target_path='Data')\n",
        "\n",
        "#create a dataset referencing the cloud location\n",
        "ds = Dataset.Tabular.from_delimited_files(datastore.path('Data/finance.csv'))\n",
        "\n",
        "financial = ds.register(workspace=ws, name='finance1_ds', description='finance training data')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 5 files\nUploading Data/.amlignore\nUploaded Data/.amlignore, 1 files out of an estimated total of 5\nUploading Data/.amlignore.amltmp\nUploaded Data/.amlignore.amltmp, 2 files out of an estimated total of 5\nUploading Data/Dataset1.csv\nUploaded Data/Dataset1.csv, 3 files out of an estimated total of 5\nUploading Data/Dataset2.csv\nUploaded Data/Dataset2.csv, 4 files out of an estimated total of 5\nUploading Data/finance.csv\nUploaded Data/finance.csv, 5 files out of an estimated total of 5\nUploaded 5 files\n"
        }
      ],
      "execution_count": 54,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728495605928
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We will now be deploying the model\n",
        "Define an environment\n",
        "When you run a Python script as an experiment in Azure Machine Learning, a Conda environment is created to define the execution context for the script. Azure Machine Learning provides a default environment that includes many common packages; including the azureml-defaults package that contains the libraries necessary for working with an experiment run, as well as popular packages like pandas and numpy.\n",
        "\n",
        "You can also define your own environment and add packages by using conda or pip, to ensure your experiment has access to all the libraries it requires."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# Create a Python environment for the experiment\n",
        "financial_env = Environment(\"financial-experiment-env\")\n",
        "financial_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
        "#financial_env.docker.enabled = True # Use a docker container\n",
        "\n",
        "# Create a set of package dependencies (conda or pip as required)\n",
        "financial_packages = CondaDependencies.create(conda_packages=['scikit-learn','ipykernel','matplotlib','pandas','pip'],\n",
        "                                             pip_packages=['azureml-sdk','pyarrow', 'azureml-defaults'])\n",
        "\n",
        "# Add the dependencies to the environment\n",
        "financial_env.python.conda_dependencies = financial_packages\n",
        "\n",
        "print(financial_env.name, 'environment defined and registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "financial-experiment-env environment defined and registered.\n"
        }
      ],
      "execution_count": 55,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728495808556
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register the environment\n",
        "Having gone to the trouble of defining an environment with the packages you need, you can register it in the workspace."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Register the environment to the workspace (optional)\n",
        "financial_env.register(workspace=ws)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 57,
          "data": {
            "text/plain": "{\n    \"assetId\": \"azureml://locations/westeurope/workspaces/18c17ad4-3053-4e1c-9f25-69c80eb22a73/environments/financial-experiment-env/versions/1\",\n    \"databricks\": {\n        \"eggLibraries\": [],\n        \"jarLibraries\": [],\n        \"mavenLibraries\": [],\n        \"pypiLibraries\": [],\n        \"rcranLibraries\": []\n    },\n    \"docker\": {\n        \"arguments\": [],\n        \"baseDockerfile\": null,\n        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20240908.v1\",\n        \"baseImageRegistry\": {\n            \"address\": null,\n            \"password\": null,\n            \"registryIdentity\": null,\n            \"username\": null\n        },\n        \"buildContext\": null,\n        \"enabled\": false,\n        \"platform\": {\n            \"architecture\": \"amd64\",\n            \"os\": \"Linux\"\n        },\n        \"sharedVolumes\": true,\n        \"shmSize\": null\n    },\n    \"environmentVariables\": {\n        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n    },\n    \"inferencingStackVersion\": null,\n    \"name\": \"financial-experiment-env\",\n    \"python\": {\n        \"baseCondaEnvironment\": null,\n        \"condaDependencies\": {\n            \"channels\": [\n                \"anaconda\",\n                \"conda-forge\"\n            ],\n            \"dependencies\": [\n                \"python=3.9.12\",\n                {\n                    \"pip\": [\n                        \"azureml-sdk\",\n                        \"pyarrow\",\n                        \"azureml-defaults\"\n                    ]\n                },\n                \"scikit-learn\",\n                \"ipykernel\",\n                \"matplotlib\",\n                \"pandas\",\n                \"pip\"\n            ],\n            \"name\": \"project_environment\"\n        },\n        \"condaDependenciesFile\": null,\n        \"interpreterPath\": \"python\",\n        \"userManagedDependencies\": false\n    },\n    \"r\": null,\n    \"spark\": {\n        \"packages\": [],\n        \"precachePackages\": true,\n        \"repositories\": []\n    },\n    \"version\": \"1\"\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 57,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728495880133
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View registered environments\n",
        "In addition to registering your own environments, you can leverage pre-built \"curated\" environments for common experiment types. The following code lists all registered environments:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "envs = Environment.list(workspace=ws)\n",
        "for env in envs:\n",
        "    print(\"Name\",env)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name financial-experiment-env\nName AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu\n"
        }
      ],
      "execution_count": 58,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728495909118
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "experiment_folder = 'finance_training_folder'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "finance_training_folder folder created\n"
        }
      ],
      "execution_count": 59,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728495937597
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the training script"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/finance_training.py\n",
        "# Import libraries\n",
        "import argparse\n",
        "from azureml.core import Run\n",
        "from azureml.core import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get script arguments\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id')\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the finance data (passed as an input dataset)\n",
        "print(\"Loading Data...\")\n",
        "finance = run.input_datasets['training_data'].to_pandas_dataframe()\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = finance[['Age', 'CustomerSince', 'HighestSpend', 'HiddenScore', 'MonthlyAverageSpend', 'Level', 'Mortgage', 'Security',\n",
        "       'FixedDepositAccount', 'InternetBanking', 'CreditCard']].values, finance['LoanOnCard'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
        "\n",
        "# Train a logistic regression model\n",
        "print('Training a logistic regression model')\n",
        "model = LogisticRegression(solver = 'liblinear', multi_class= 'auto', max_iter=200).fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
        "joblib.dump(value=model, filename='outputs/finance_model.pkl')\n",
        "\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing finance_training_folder/finance_training.py\n"
        }
      ],
      "execution_count": 61,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728496074685
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run an experiment on remote compute\n",
        "Now you're ready to re-run the experiment you ran previously, but this time on the compute cluster you created."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "#replace this with your cluster name\n",
        "cluster_name = \"cb-aml-cluster\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS3_V2', max_nodes=4)\n",
        "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        training_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 62,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728496289988
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from azureml.core import Workspace, Experiment, ScriptRunConfig, Environment, Dataset\n",
        "\n",
        "\n",
        "# Step 1: Connect to the Azure ML workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Step 2: Get the training dataset\n",
        "financial_ds = Dataset.get_by_name(ws, name=\"finance1_ds\")  # Replace with your dataset name if needed\n",
        "\n",
        "# Step 3: Retrieve the registered environment\n",
        "registered_env = Environment.get(workspace=ws, name='financial-experiment-env')\n",
        "\n",
        "# Step 4: Create the ScriptRunConfig\n",
        "# Specify the folder where your Python training script is located\n",
        "experiment_folder = './finance_training_folder'\n",
        "\n",
        "\n",
        "# Set the compute target name\n",
        "compute_target = \"cb-aml-cluster\"  # Replace with your cluster name\n",
        "\n",
        "# Define the configuration for running the script\n",
        "script_config = ScriptRunConfig(\n",
        "    source_directory=experiment_folder,\n",
        "    script='finance_training.py',  # Name of your training script\n",
        "    arguments=['--input-data', financial_ds.as_named_input('training_data')],  # Pass dataset as named input\n",
        "    environment=registered_env,  # Use the registered environment\n",
        "    compute_target=compute_target  # Specify the compute target\n",
        ")\n",
        "\n",
        "# Step 5: Submit the experiment\n",
        "experiment_name = 'cbml-train-finance'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "\n",
        "# Submit the experiment and get the run object\n",
        "run = experiment.submit(config=script_config)\n",
        "\n",
        "\n",
        "# Step 7: Wait for the run to complete\n",
        "run.wait_for_completion(show_output=True)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: cbml-train-finance_1728497564_e1e3bcaf\nWeb View: https://ml.azure.com/runs/cbml-train-finance_1728497564_e1e3bcaf?wsid=/subscriptions/805e2807-b34c-423a-83fb-6c6c635d5b7a/resourcegroups/rg-contosobank-lf66db13b49ae47f691/workspaces/mlw-cb-lf66db13b49ae47f691&tid=d83a6143-104d-46a7-987d-230c352019f1\n\nStreaming azureml-logs/20_image_build_log.txt\n=============================================\n\n======Starting Image Build on Serverless Compute======\nThe run ID for the image build on serverless compute is imgbldrun_e508229\nAdditional logs for the run: https://ml.azure.com/experiments/id/prepare_image/runs/imgbldrun_e508229?wsid=/subscriptions/805e2807-b34c-423a-83fb-6c6c635d5b7a/resourcegroups/rg-contosobank-lf66db13b49ae47f691/workspaces/mlw-cb-lf66db13b49ae47f691&tid=d83a6143-104d-46a7-987d-230c352019f1\n2024-10-09T18:16:29: Logging into Docker registry: 18c17ad430534e1c9f2569c80eb22a73.azurecr.io\n2024-10-09T18:16:29: WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n2024-10-09T18:16:29: WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n2024-10-09T18:16:29: Configure a credential helper to remove this warning. See\n2024-10-09T18:16:29: https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\n2024-10-09T18:16:29: Login Succeeded\n\n\n2024-10-09T18:16:29: Running: ['docker', 'build', '-f', 'azureml-environment-setup/Dockerfile', '.', '-t', '18c17ad430534e1c9f2569c80eb22a73.azurecr.io/azureml/azureml_ef40939cb933183bffcbfd8160e11fcf', '-t', '18c17ad430534e1c9f2569c80eb22a73.azurecr.io/azureml/azureml_ef40939cb933183bffcbfd8160e11fcf:1']\n2024-10-09T18:16:29: DEPRECATED: The legacy builder is deprecated and will be removed in a future release.\n2024-10-09T18:16:29:             Install the buildx component to build images with BuildKit:\n2024-10-09T18:16:29:             https://docs.docker.com/go/buildx/\n\n2024-10-09T18:16:29: Sending build context to Docker daemon  71.17kB\n2024-10-09T18:16:29: Step 1/17 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20240908.v1@sha256:3b5eac3407d396ac16e4f8da93cffe8d0c96c1e06d474513b7ccdf0dd60a5fc7\n2024-10-09T18:16:29: mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20240908.v1@sha256:3b5eac3407d396ac16e4f8da93cffe8d0c96c1e06d474513b7ccdf0dd60a5fc7: Pulling from azureml/openmpi4.1.0-ubuntu20.04\n2024-10-09T18:16:29: 560c024910be: Pulling fs layer\n2024-10-09T18:16:29: 02760d89aac5: Pulling fs layer\n2024-10-09T18:16:29: 30ccad6526b5: Pulling fs layer\n2024-10-09T18:16:29: e79ce12181a6: Pulling fs layer\n2024-10-09T18:16:29: f50879c9b280: Pulling fs layer\n2024-10-09T18:16:29: d27a65543cb4: Pulling fs layer\n2024-10-09T18:16:29: 0a3af90e1fb4: Pulling fs layer\n2024-10-09T18:16:29: d7baf0697f41: Pulling fs layer\n2024-10-09T18:16:29: 99f2fb6889d7: Pulling fs layer\n2024-10-09T18:16:29: 4e3b4c0361fb: Pulling fs layer\n2024-10-09T18:16:29: e79ce12181a6: Waiting\n2024-10-09T18:16:29: f50879c9b280: Waiting\n2024-10-09T18:16:29: d27a65543cb4: Waiting\n2024-10-09T18:16:29: 0a3af90e1fb4: Waiting\n2024-10-09T18:16:29: d7baf0697f41: Waiting\n2024-10-09T18:16:29: 99f2fb6889d7: Waiting\n2024-10-09T18:16:29: 4e3b4c0361fb: Waiting\n2024-10-09T18:16:29: 30ccad6526b5: Download complete\n2024-10-09T18:16:30: 560c024910be: Verifying Checksum\n2024-10-09T18:16:30: 560c024910be: Download complete\n2024-10-09T18:16:30: e79ce12181a6: Verifying Checksum\n2024-10-09T18:16:30: e79ce12181a6: Download complete\n2024-10-09T18:16:30: f50879c9b280: Verifying Checksum\n2024-10-09T18:16:30: f50879c9b280: Download complete\n2024-10-09T18:16:30: 0a3af90e1fb4: Verifying Checksum\n2024-10-09T18:16:30: 0a3af90e1fb4: Download complete\n2024-10-09T18:16:30: d7baf0697f41: Verifying Checksum\n2024-10-09T18:16:30: d7baf0697f41: Download complete\n2024-10-09T18:16:30: d27a65543cb4: Verifying Checksum\n2024-10-09T18:16:30: d27a65543cb4: Download complete\n2024-10-09T18:16:30: 02760d89aac5: Verifying Checksum\n2024-10-09T18:16:30: 02760d89aac5: Download complete\n2024-10-09T18:16:30: 99f2fb6889d7: Verifying Checksum\n2024-10-09T18:16:30: 99f2fb6889d7: Download complete\n2024-10-09T18:16:31: 4e3b4c0361fb: Download complete\n2024-10-09T18:16:31: 560c024910be: Pull complete\n2024-10-09T18:16:41: 02760d89aac5: Pull complete\n2024-10-09T18:16:41: 30ccad6526b5: Pull complete\n2024-10-09T18:16:42: e79ce12181a6: Pull complete\n2024-10-09T18:16:42: f50879c9b280: Pull complete\n2024-10-09T18:16:47: d27a65543cb4: Pull complete\n2024-10-09T18:16:48: 0a3af90e1fb4: Pull complete\n2024-10-09T18:16:49: d7baf0697f41: Pull complete\n2024-10-09T18:16:49: 99f2fb6889d7: Pull complete\n2024-10-09T18:16:49: 4e3b4c0361fb: Pull complete\n2024-10-09T18:16:49: Digest: sha256:3b5eac3407d396ac16e4f8da93cffe8d0c96c1e06d474513b7ccdf0dd60a5fc7\n2024-10-09T18:16:49: Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20240908.v1@sha256:3b5eac3407d396ac16e4f8da93cffe8d0c96c1e06d474513b7ccdf0dd60a5fc7\n2024-10-09T18:16:49:  ---> a3a4d2d202cc\n2024-10-09T18:16:49: Step 2/17 : USER root\n2024-10-09T18:16:49:  ---> Running in 43594b3c9966\n2024-10-09T18:16:50: Removing intermediate container 43594b3c9966\n2024-10-09T18:16:50:  ---> 53805e1066fb\n2024-10-09T18:16:50: Step 3/17 : RUN mkdir -p $HOME/.cache\n2024-10-09T18:16:50:  ---> Running in 80ae8b80b113\n2024-10-09T18:16:52: Removing intermediate container 80ae8b80b113\n2024-10-09T18:16:52:  ---> 07d40ec9e070\n2024-10-09T18:16:52: Step 4/17 : WORKDIR /\n2024-10-09T18:16:52:  ---> Running in 9e910a58e361\n2024-10-09T18:16:53: Removing intermediate container 9e910a58e361\n2024-10-09T18:16:53:  ---> 9a92ab398819\n2024-10-09T18:16:53: Step 5/17 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n2024-10-09T18:16:54:  ---> 1b3a2e7e20ff\n2024-10-09T18:16:54: Step 6/17 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n2024-10-09T18:16:54:  ---> Running in 50c2df0c51df\n2024-10-09T18:16:56: Removing intermediate container 50c2df0c51df\n2024-10-09T18:16:56:  ---> 3b1d3f3a391b\n2024-10-09T18:16:56: Step 7/17 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n2024-10-09T18:16:57:  ---> 87b902ad2536\n2024-10-09T18:16:57: Step 8/17 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n2024-10-09T18:16:57:  ---> Running in ae9e1645328d\n2024-10-09T18:16:58: Retrieving notices: ...working... done\n2024-10-09T18:16:58: Channels:\n2024-10-09T18:16:58:  - anaconda\n2024-10-09T18:16:58:  - conda-forge\n2024-10-09T18:16:58:  - defaults\n2024-10-09T18:16:58: Platform: linux-64\n2024-10-09T18:17:16: Collecting package metadata (repodata.json): ...working... done\n2024-10-09T18:17:20: Solving environment: ...working... done\n2024-10-09T18:17:20: \n\n2024-10-09T18:17:20: ==> WARNING: A newer version of conda exists. <==\n2024-10-09T18:17:20:     current version: 24.7.1\n2024-10-09T18:17:20:     latest version: 24.9.1\n\n2024-10-09T18:17:20: Please update conda by running\n\n2024-10-09T18:17:20:     $ conda update -n base -c conda-forge conda\n\n\n2024-10-09T18:18:07: \n2024-10-09T18:18:07: Downloading and Extracting Packages: ...working... done\n2024-10-09T18:18:08: Preparing transaction: ...working... done\n2024-10-09T18:18:15: Verifying transaction: ...working... done\n2024-10-09T18:18:21: Executing transaction: ...working... done\n2024-10-09T18:19:03: Installing pip dependencies: ...working... Ran pip subprocess with arguments:\n2024-10-09T18:19:03: ['/azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.8cfsycb_.requirements.txt', '--exists-action=b']\n2024-10-09T18:19:03: Pip subprocess output:\n2024-10-09T18:19:03: Collecting azureml-sdk (from -r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azureml_sdk-1.57.0-py3-none-any.whl.metadata (3.5 kB)\n2024-10-09T18:19:03: Collecting pyarrow (from -r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 2))\n2024-10-09T18:19:03:   Downloading pyarrow-17.0.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n2024-10-09T18:19:03: Collecting azureml-defaults (from -r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading azureml_defaults-1.57.0.post1-py3-none-any.whl.metadata (738 bytes)\n2024-10-09T18:19:03: Collecting azureml-core~=1.57.0 (from azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azureml_core-1.57.0.post3-py3-none-any.whl.metadata (3.1 kB)\n2024-10-09T18:19:03: Collecting azureml-dataset-runtime~=1.57.0 (from azureml-dataset-runtime[fuse]~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azureml_dataset_runtime-1.57.0-py3-none-any.whl.metadata (1.2 kB)\n2024-10-09T18:19:03: Collecting azureml-train-core~=1.57.0 (from azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azureml_train_core-1.57.0-py3-none-any.whl.metadata (1.7 kB)\n2024-10-09T18:19:03: Collecting azureml-train-automl-client~=1.57.0 (from azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azureml_train_automl_client-1.57.0-py3-none-any.whl.metadata (1.4 kB)\n2024-10-09T18:19:03: Collecting azureml-pipeline~=1.57.0 (from azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azureml_pipeline-1.57.0-py3-none-any.whl.metadata (1.7 kB)\n2024-10-09T18:19:03: Requirement already satisfied: numpy>=1.16.6 in /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7/lib/python3.9/site-packages (from pyarrow->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 2)) (1.26.4)\n2024-10-09T18:19:03: Collecting azureml-inference-server-http~=1.3 (from azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading azureml_inference_server_http-1.3.3-py3-none-any.whl.metadata (10 kB)\n2024-10-09T18:19:03: Requirement already satisfied: pytz in /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7/lib/python3.9/site-packages (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1)) (2024.1)\n2024-10-09T18:19:03: Collecting backports.tempfile (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading backports.tempfile-1.0-py2.py3-none-any.whl.metadata (2.3 kB)\n2024-10-09T18:19:03: Collecting pathspec<1.0.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n2024-10-09T18:19:03: Collecting requests<3.0.0,>=2.19.1 (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n2024-10-09T18:19:03: Collecting msal<2.0.0,>=1.15.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading msal-1.31.0-py3-none-any.whl.metadata (11 kB)\n2024-10-09T18:19:03: Collecting msal-extensions<=2.0.0,>=0.3.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading msal_extensions-1.2.0-py3-none-any.whl.metadata (7.6 kB)\n2024-10-09T18:19:03: Collecting knack<0.12.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading knack-0.11.0-py3-none-any.whl.metadata (5.2 kB)\n2024-10-09T18:19:03: Collecting azure-core<2.0.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azure_core-1.31.0-py3-none-any.whl.metadata (39 kB)\n2024-10-09T18:19:03: Collecting pkginfo (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading pkginfo-1.11.1-py3-none-any.whl.metadata (11 kB)\n2024-10-09T18:19:03: Collecting argcomplete<4 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading argcomplete-3.5.1-py3-none-any.whl.metadata (16 kB)\n2024-10-09T18:19:03: Collecting humanfriendly<11.0,>=4.7 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n2024-10-09T18:19:03: Collecting paramiko<4.0.0,>=2.0.8 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading paramiko-3.5.0-py3-none-any.whl.metadata (4.4 kB)\n2024-10-09T18:19:03: Collecting azure-mgmt-resource<=24.0.0,>=15.0.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azure_mgmt_resource-23.1.1-py3-none-any.whl.metadata (37 kB)\n2024-10-09T18:19:03: Collecting azure-mgmt-containerregistry<11,>=8.2.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azure_mgmt_containerregistry-10.3.0-py3-none-any.whl.metadata (23 kB)\n2024-10-09T18:19:03: Collecting azure-mgmt-storage<=22.0.0,>=16.0.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azure_mgmt_storage-21.2.1-py3-none-any.whl.metadata (31 kB)\n2024-10-09T18:19:03: Collecting azure-mgmt-keyvault<11.0.0,>=0.40.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azure_mgmt_keyvault-10.3.1-py3-none-any.whl.metadata (15 kB)\n2024-10-09T18:19:03: Collecting azure-mgmt-authorization<5,>=0.40.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azure_mgmt_authorization-4.0.0-py3-none-any.whl.metadata (18 kB)\n2024-10-09T18:19:03: Collecting azure-mgmt-network<=26.0.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azure_mgmt_network-26.0.0-py3-none-any.whl.metadata (84 kB)\n2024-10-09T18:19:03: Collecting azure-graphrbac<1.0.0,>=0.40.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl.metadata (10 kB)\n2024-10-09T18:19:03: Collecting azure-common<2.0.0,>=1.1.12 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n2024-10-09T18:19:03: Collecting msrest<=0.7.1,>=0.5.1 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n2024-10-09T18:19:03: Collecting msrestazure<=0.7,>=0.4.33 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading msrestazure-0.6.4.post1-py2.py3-none-any.whl.metadata (15 kB)\n2024-10-09T18:19:03: Collecting urllib3<3.0.0,>1.26.17 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n2024-10-09T18:19:03: Requirement already satisfied: packaging<=25.0,>=20.0 in /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7/lib/python3.9/site-packages (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1)) (24.1)\n2024-10-09T18:19:03: Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7/lib/python3.9/site-packages (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1)) (2.9.0.post0)\n2024-10-09T18:19:03: Collecting ndg-httpsclient<=0.5.1 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading ndg_httpsclient-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n2024-10-09T18:19:03: Collecting SecretStorage<4.0.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading SecretStorage-3.3.3-py3-none-any.whl.metadata (4.0 kB)\n2024-10-09T18:19:03: Collecting jsonpickle<4.0.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading jsonpickle-3.3.0-py3-none-any.whl.metadata (8.3 kB)\n2024-10-09T18:19:03: Collecting contextlib2<22.0.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n2024-10-09T18:19:03: Collecting docker<8.0.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n2024-10-09T18:19:03: Collecting PyJWT<3.0.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\n2024-10-09T18:19:03: Collecting adal<=1.2.7,>=1.2.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading adal-1.2.7-py2.py3-none-any.whl.metadata (6.9 kB)\n2024-10-09T18:19:03: Collecting pyopenssl<25.0.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading pyOpenSSL-24.2.1-py3-none-any.whl.metadata (13 kB)\n2024-10-09T18:19:03: Collecting jmespath<2.0.0 (from azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n2024-10-09T18:19:03: Collecting azureml-dataprep<5.2.0a,>=5.1.0a (from azureml-dataset-runtime~=1.57.0->azureml-dataset-runtime[fuse]~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azureml_dataprep-5.1.6-py3-none-any.whl.metadata (2.2 kB)\n2024-10-09T18:19:03: Collecting numpy>=1.16.6 (from pyarrow->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 2))\n2024-10-09T18:19:03:   Downloading numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n2024-10-09T18:19:03: Collecting fusepy<4.0.0,>=3.0.1 (from azureml-dataset-runtime[fuse]~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading fusepy-3.0.1.tar.gz (11 kB)\n2024-10-09T18:19:03:   Preparing metadata (setup.py): started\n2024-10-09T18:19:03:   Preparing metadata (setup.py): finished with status 'done'\n2024-10-09T18:19:03: Collecting flask<=2.3.2 (from azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading Flask-2.3.2-py3-none-any.whl.metadata (3.7 kB)\n2024-10-09T18:19:03: Collecting flask-cors~=5.0.0 (from azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n2024-10-09T18:19:03: Collecting inference-schema~=1.8.0 (from azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading inference_schema-1.8-py3-none-any.whl.metadata (2.5 kB)\n2024-10-09T18:19:03: Collecting opencensus-ext-azure~=1.1.0 (from azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading opencensus_ext_azure-1.1.13-py2.py3-none-any.whl.metadata (16 kB)\n2024-10-09T18:19:03: Collecting pydantic~=2.7.1 (from azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n2024-10-09T18:19:03: Collecting pydantic-settings (from azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n2024-10-09T18:19:03: Collecting werkzeug>=3.0.3 (from azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n2024-10-09T18:19:03: Collecting certifi>=2024.7.4 (from azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n2024-10-09T18:19:03: Collecting gunicorn==22.0.0 (from azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading gunicorn-22.0.0-py3-none-any.whl.metadata (4.4 kB)\n2024-10-09T18:19:03: Collecting azureml-pipeline-core~=1.57.0 (from azureml-pipeline~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azureml_pipeline_core-1.57.0-py3-none-any.whl.metadata (961 bytes)\n2024-10-09T18:19:03: Collecting azureml-pipeline-steps~=1.57.0 (from azureml-pipeline~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azureml_pipeline_steps-1.57.0-py3-none-any.whl.metadata (1.1 kB)\n2024-10-09T18:19:03: Collecting azureml-automl-core~=1.57.0 (from azureml-train-automl-client~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azureml_automl_core-1.57.0-py3-none-any.whl.metadata (1.8 kB)\n2024-10-09T18:19:03: Collecting azureml-telemetry~=1.57.0 (from azureml-train-automl-client~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azureml_telemetry-1.57.0-py3-none-any.whl.metadata (1.1 kB)\n2024-10-09T18:19:03: Collecting azureml-train-restclients-hyperdrive~=1.57.0 (from azureml-train-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azureml_train_restclients_hyperdrive-1.57.0-py3-none-any.whl.metadata (1.2 kB)\n2024-10-09T18:19:03: Collecting cryptography>=1.1.0 (from adal<=1.2.7,>=1.2.0->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading cryptography-43.0.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n2024-10-09T18:19:03: Requirement already satisfied: six>=1.11.0 in /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7/lib/python3.9/site-packages (from azure-core<2.0.0->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1)) (1.16.0)\n2024-10-09T18:19:03: Requirement already satisfied: typing-extensions>=4.6.0 in /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7/lib/python3.9/site-packages (from azure-core<2.0.0->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1)) (4.11.0)\n2024-10-09T18:19:03: Collecting isodate<1.0.0,>=0.6.1 (from azure-mgmt-authorization<5,>=0.40.0->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n2024-10-09T18:19:03: Collecting azure-mgmt-core<2.0.0,>=1.3.2 (from azure-mgmt-authorization<5,>=0.40.0->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azure_mgmt_core-1.4.0-py3-none-any.whl.metadata (4.1 kB)\n2024-10-09T18:19:03: Requirement already satisfied: importlib-metadata<=8.2.0 in /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7/lib/python3.9/site-packages (from azureml-automl-core~=1.57.0->azureml-train-automl-client~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1)) (7.0.1)\n2024-10-09T18:19:03: Requirement already satisfied: importlib-resources<=6.4.0 in /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7/lib/python3.9/site-packages (from azureml-automl-core~=1.57.0->azureml-train-automl-client~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1)) (6.4.0)\n2024-10-09T18:19:03: Collecting azureml-dataprep-native<42.0.0,>=41.0.0 (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.57.0->azureml-dataset-runtime[fuse]~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azureml_dataprep_native-41.0.0-cp39-cp39-manylinux1_x86_64.whl.metadata (1.3 kB)\n2024-10-09T18:19:03: Collecting azureml-dataprep-rslex~=2.22.2dev0 (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.57.0->azureml-dataset-runtime[fuse]~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azureml_dataprep_rslex-2.22.4-cp39-cp39-manylinux1_x86_64.whl.metadata (1.6 kB)\n2024-10-09T18:19:03: Collecting cloudpickle<3.0.0,>=1.1.0 (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.57.0->azureml-dataset-runtime[fuse]~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n2024-10-09T18:19:03: Collecting azure-identity>=1.7.0 (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.57.0->azureml-dataset-runtime[fuse]~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading azure_identity-1.19.0-py3-none-any.whl.metadata (80 kB)\n2024-10-09T18:19:03: Collecting jsonschema (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.57.0->azureml-dataset-runtime[fuse]~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n2024-10-09T18:19:03: Collecting pyyaml<7.0.0,>=5.1.0 (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.57.0->azureml-dataset-runtime[fuse]~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n2024-10-09T18:19:03: Collecting applicationinsights (from azureml-telemetry~=1.57.0->azureml-train-automl-client~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading applicationinsights-0.11.10-py2.py3-none-any.whl.metadata (982 bytes)\n2024-10-09T18:19:03: Collecting Jinja2>=3.1.2 (from flask<=2.3.2->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n2024-10-09T18:19:03: Collecting itsdangerous>=2.1.2 (from flask<=2.3.2->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n2024-10-09T18:19:03: Collecting click>=8.1.3 (from flask<=2.3.2->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n2024-10-09T18:19:03: Collecting blinker>=1.6.2 (from flask<=2.3.2->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n2024-10-09T18:19:03: Collecting wrapt<=1.16.0,>=1.14.0 (from inference-schema~=1.8.0->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading wrapt-1.16.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n2024-10-09T18:19:03: Requirement already satisfied: pygments in /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7/lib/python3.9/site-packages (from knack<0.12.0->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1)) (2.15.1)\n2024-10-09T18:19:03: Collecting tabulate (from knack<0.12.0->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n2024-10-09T18:19:03: Collecting portalocker<3,>=1.4 (from msal-extensions<=2.0.0,>=0.3.0->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n2024-10-09T18:19:03: Collecting requests-oauthlib>=0.5.0 (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n2024-10-09T18:19:03: Collecting pyasn1>=0.1.1 (from ndg-httpsclient<=0.5.1->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n2024-10-09T18:19:03: Collecting opencensus<1.0.0,>=0.11.4 (from opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n2024-10-09T18:19:03: Requirement already satisfied: psutil>=5.6.3 in /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7/lib/python3.9/site-packages (from opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3)) (5.9.0)\n2024-10-09T18:19:03: Collecting bcrypt>=3.2 (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n2024-10-09T18:19:03: Collecting pynacl>=1.5 (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n2024-10-09T18:19:03: Collecting annotated-types>=0.4.0 (from pydantic~=2.7.1->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n2024-10-09T18:19:03: Collecting pydantic-core==2.18.4 (from pydantic~=2.7.1->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading pydantic_core-2.18.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n2024-10-09T18:19:03: Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.19.1->requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading charset_normalizer-3.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n2024-10-09T18:19:03: Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.19.1->requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n2024-10-09T18:19:03: Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n2024-10-09T18:19:03: Collecting jeepney>=0.6 (from SecretStorage<4.0.0->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading jeepney-0.8.0-py3-none-any.whl.metadata (1.3 kB)\n2024-10-09T18:19:03: Collecting MarkupSafe>=2.1.1 (from werkzeug>=3.0.3->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading MarkupSafe-3.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n2024-10-09T18:19:03: Collecting backports.weakref (from backports.tempfile->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl.metadata (2.3 kB)\n2024-10-09T18:19:03: Collecting python-dotenv>=0.21.0 (from pydantic-settings->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n2024-10-09T18:19:03: Collecting cffi>=1.12 (from cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading cffi-1.17.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n2024-10-09T18:19:03: Requirement already satisfied: zipp>=0.5 in /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7/lib/python3.9/site-packages (from importlib-metadata<=8.2.0->azureml-automl-core~=1.57.0->azureml-train-automl-client~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1)) (3.17.0)\n2024-10-09T18:19:03: Collecting opencensus-context>=0.1.3 (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n2024-10-09T18:19:03: Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading google_api_core-2.21.0-py3-none-any.whl.metadata (2.8 kB)\n2024-10-09T18:19:03: Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n2024-10-09T18:19:03: Collecting attrs>=22.2.0 (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.57.0->azureml-dataset-runtime[fuse]~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n2024-10-09T18:19:03: Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.57.0->azureml-dataset-runtime[fuse]~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n2024-10-09T18:19:03: Collecting referencing>=0.28.4 (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.57.0->azureml-dataset-runtime[fuse]~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n2024-10-09T18:19:03: Collecting rpds-py>=0.7.1 (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.57.0->azureml-dataset-runtime[fuse]~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading rpds_py-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n2024-10-09T18:19:03: Collecting pycparser (from cffi>=1.12->cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core~=1.57.0->azureml-sdk->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 1))\n2024-10-09T18:19:03:   Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n2024-10-09T18:19:03: Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n2024-10-09T18:19:03: Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n2024-10-09T18:19:03: Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n2024-10-09T18:19:03: Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n2024-10-09T18:19:03: Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n2024-10-09T18:19:03: Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n2024-10-09T18:19:03: Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=1.3->azureml-defaults->-r /azureml-environment-setup/condaenv.8cfsycb_.requirements.txt (line 3))\n2024-10-09T18:19:03:   Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n2024-10-09T18:19:03: Downloading azureml_sdk-1.57.0-py3-none-any.whl (2.7 kB)\n2024-10-09T18:19:03: Downloading pyarrow-17.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (39.9 MB)\n2024-10-09T18:19:03:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.9/39.9 MB 75.5 MB/s eta 0:00:00\n2024-10-09T18:19:03: Downloading azureml_defaults-1.57.0.post1-py3-none-any.whl (2.0 kB)\n2024-10-09T18:19:03: Downloading azureml_core-1.57.0.post3-py3-none-any.whl (3.3 MB)\n2024-10-09T18:19:03:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 95.3 MB/s eta 0:00:00\n2024-10-09T18:19:03: Downloading azureml_dataset_runtime-1.57.0-py3-none-any.whl (2.2 kB)\n2024-10-09T18:19:03: Downloading azureml_inference_server_http-1.3.3-py3-none-any.whl (42 kB)\n2024-10-09T18:19:03: Downloading gunicorn-22.0.0-py3-none-any.whl (84 kB)\n2024-10-09T18:19:03: Downloading azureml_pipeline-1.57.0-py3-none-any.whl (2.4 kB)\n2024-10-09T18:19:03: Downloading azureml_train_automl_client-1.57.0-py3-none-any.whl (137 kB)\n2024-10-09T18:19:03: Downloading azureml_train_core-1.57.0-py3-none-any.whl (8.6 MB)\n2024-10-09T18:19:03:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 123.9 MB/s eta 0:00:00\n2024-10-09T18:19:03: Downloading numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n2024-10-09T18:19:03:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.1/17.1 MB 100.4 MB/s eta 0:00:00\n2024-10-09T18:19:03: Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n2024-10-09T18:19:03: Downloading argcomplete-3.5.1-py3-none-any.whl (43 kB)\n2024-10-09T18:19:03: Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n2024-10-09T18:19:03: Downloading azure_core-1.31.0-py3-none-any.whl (197 kB)\n2024-10-09T18:19:03: Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n2024-10-09T18:19:03: Downloading azure_mgmt_authorization-4.0.0-py3-none-any.whl (1.1 MB)\n2024-10-09T18:19:03:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 33.8 MB/s eta 0:00:00\n2024-10-09T18:19:03: Downloading azure_mgmt_containerregistry-10.3.0-py3-none-any.whl (2.3 MB)\n2024-10-09T18:19:03:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 78.9 MB/s eta 0:00:00\n2024-10-09T18:19:03: Downloading azure_mgmt_keyvault-10.3.1-py3-none-any.whl (901 kB)\n2024-10-09T18:19:03:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 901.4/901.4 kB 30.9 MB/s eta 0:00:00\n2024-10-09T18:19:03: Downloading azure_mgmt_network-26.0.0-py3-none-any.whl (617 kB)\n2024-10-09T18:19:03:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 617.4/617.4 kB 25.0 MB/s eta 0:00:00\n2024-10-09T18:19:03: Downloading azure_mgmt_resource-23.1.1-py3-none-any.whl (2.6 MB)\n2024-10-09T18:19:03:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.6/2.6 MB 72.6 MB/s eta 0:00:00\n2024-10-09T18:19:03: Downloading azure_mgmt_storage-21.2.1-py3-none-any.whl (3.2 MB)\n2024-10-09T18:19:03:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 90.4 MB/s eta 0:00:00\n2024-10-09T18:19:03: Downloading azureml_automl_core-1.57.0-py3-none-any.whl (249 kB)\n2024-10-09T18:19:03: Downloading azureml_dataprep-5.1.6-py3-none-any.whl (252 kB)\n2024-10-09T18:19:03: Downloading azureml_pipeline_core-1.57.0-py3-none-any.whl (313 kB)\n2024-10-09T18:19:03: Downloading azureml_pipeline_steps-1.57.0-py3-none-any.whl (69 kB)\n2024-10-09T18:19:03: Downloading azureml_telemetry-1.57.0-py3-none-any.whl (30 kB)\n2024-10-09T18:19:03: Downloading azureml_train_restclients_hyperdrive-1.57.0-py3-none-any.whl (18 kB)\n2024-10-09T18:19:03: Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n2024-10-09T18:19:03: Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n2024-10-09T18:19:03: Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n2024-10-09T18:19:03: Downloading Flask-2.3.2-py3-none-any.whl (96 kB)\n2024-10-09T18:19:03: Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n2024-10-09T18:19:03: Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n2024-10-09T18:19:03: Downloading inference_schema-1.8-py3-none-any.whl (21 kB)\n2024-10-09T18:19:03: Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n2024-10-09T18:19:03: Downloading jsonpickle-3.3.0-py3-none-any.whl (42 kB)\n2024-10-09T18:19:03: Downloading knack-0.11.0-py3-none-any.whl (60 kB)\n2024-10-09T18:19:03: Downloading msal-1.31.0-py3-none-any.whl (113 kB)\n2024-10-09T18:19:03: Downloading msal_extensions-1.2.0-py3-none-any.whl (19 kB)\n2024-10-09T18:19:03: Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n2024-10-09T18:19:03: Downloading msrestazure-0.6.4.post1-py2.py3-none-any.whl (40 kB)\n2024-10-09T18:19:03: Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n2024-10-09T18:19:03: Downloading opencensus_ext_azure-1.1.13-py2.py3-none-any.whl (43 kB)\n2024-10-09T18:19:03: Downloading paramiko-3.5.0-py3-none-any.whl (227 kB)\n2024-10-09T18:19:03: Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n2024-10-09T18:19:03: Downloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n2024-10-09T18:19:03: Downloading pydantic_core-2.18.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n2024-10-09T18:19:03:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 73.5 MB/s eta 0:00:00\n2024-10-09T18:19:03: Downloading PyJWT-2.9.0-py3-none-any.whl (22 kB)\n2024-10-09T18:19:03: Downloading pyOpenSSL-24.2.1-py3-none-any.whl (58 kB)\n2024-10-09T18:19:03: Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n2024-10-09T18:19:03: Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n2024-10-09T18:19:03: Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n2024-10-09T18:19:03: Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n2024-10-09T18:19:03: Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n2024-10-09T18:19:03: Downloading pkginfo-1.11.1-py3-none-any.whl (31 kB)\n2024-10-09T18:19:03: Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n2024-10-09T18:19:03: Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n2024-10-09T18:19:03: Downloading azure_identity-1.19.0-py3-none-any.whl (187 kB)\n2024-10-09T18:19:03: Downloading azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB)\n2024-10-09T18:19:03: Downloading azureml_dataprep_native-41.0.0-cp39-cp39-manylinux1_x86_64.whl (187 kB)\n2024-10-09T18:19:03: Downloading azureml_dataprep_rslex-2.22.4-cp39-cp39-manylinux1_x86_64.whl (24.8 MB)\n2024-10-09T18:19:03:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.8/24.8 MB 82.8 MB/s eta 0:00:00\n2024-10-09T18:19:03: Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n2024-10-09T18:19:03: Downloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n2024-10-09T18:19:03: Downloading charset_normalizer-3.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n2024-10-09T18:19:03: Downloading click-8.1.7-py3-none-any.whl (97 kB)\n2024-10-09T18:19:03: Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n2024-10-09T18:19:03: Downloading cryptography-43.0.1-cp39-abi3-manylinux_2_28_x86_64.whl (4.0 MB)\n2024-10-09T18:19:03:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.0/4.0 MB 107.7 MB/s eta 0:00:00\n2024-10-09T18:19:03: Downloading idna-3.10-py3-none-any.whl (70 kB)\n2024-10-09T18:19:03: Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n2024-10-09T18:19:03: Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n2024-10-09T18:19:03: Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n2024-10-09T18:19:03: Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n2024-10-09T18:19:03: Downloading MarkupSafe-3.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n2024-10-09T18:19:03: Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n2024-10-09T18:19:03: Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n2024-10-09T18:19:03: Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n2024-10-09T18:19:03: Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n2024-10-09T18:19:03:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 856.7/856.7 kB 25.3 MB/s eta 0:00:00\n2024-10-09T18:19:03: Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n2024-10-09T18:19:03: Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n2024-10-09T18:19:03: Downloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (737 kB)\n2024-10-09T18:19:03:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 737.4/737.4 kB 25.8 MB/s eta 0:00:00\n2024-10-09T18:19:03: Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n2024-10-09T18:19:03: Downloading wrapt-1.16.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n2024-10-09T18:19:03: Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n2024-10-09T18:19:03: Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n2024-10-09T18:19:03: Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n2024-10-09T18:19:03: Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n2024-10-09T18:19:03: Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n2024-10-09T18:19:03: Downloading cffi-1.17.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (445 kB)\n2024-10-09T18:19:03: Downloading google_api_core-2.21.0-py3-none-any.whl (156 kB)\n2024-10-09T18:19:03: Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n2024-10-09T18:19:03: Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n2024-10-09T18:19:03: Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n2024-10-09T18:19:03: Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n2024-10-09T18:19:03: Downloading rpds_py-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n2024-10-09T18:19:03: Downloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n2024-10-09T18:19:03: Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n2024-10-09T18:19:03: Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n2024-10-09T18:19:03: Downloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n2024-10-09T18:19:03: Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n2024-10-09T18:19:03: Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n2024-10-09T18:19:03: Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n2024-10-09T18:19:03: Downloading rsa-4.9-py3-none-any.whl (34 kB)\n2024-10-09T18:19:03: Building wheels for collected packages: fusepy\n2024-10-09T18:19:03:   Building wheel for fusepy (setup.py): started\n2024-10-09T18:19:03:   Building wheel for fusepy (setup.py): finished with status 'done'\n2024-10-09T18:19:03:   Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10486 sha256=fd18812339d5a36440c8068d52670f2dbf7b8f678b3719ccb6bbf1aa90cd83b8\n2024-10-09T18:19:03:   Stored in directory: /root/.cache/pip/wheels/d5/60/5d/807081f971b004ab5c86eba746c6b5e72d0258215bf2425d68\n2024-10-09T18:19:03: Successfully built fusepy\n2024-10-09T18:19:03: Installing collected packages: opencensus-context, fusepy, backports.weakref, azureml-dataprep-rslex, azureml-dataprep-native, azure-common, applicationinsights, wrapt, urllib3, tabulate, rpds-py, pyyaml, python-dotenv, PySocks, PyJWT, pydantic-core, pycparser, pyasn1, protobuf, portalocker, pkginfo, pathspec, oauthlib, numpy, MarkupSafe, jsonpickle, jmespath, jeepney, itsdangerous, isodate, idna, humanfriendly, gunicorn, contextlib2, cloudpickle, click, charset-normalizer, certifi, cachetools, blinker, bcrypt, backports.tempfile, attrs, argcomplete, annotated-types, werkzeug, rsa, requests, referencing, pydantic, pyasn1-modules, pyarrow, proto-plus, knack, Jinja2, inference-schema, googleapis-common-protos, cffi, requests-oauthlib, pynacl, pydantic-settings, jsonschema-specifications, google-auth, flask, docker, cryptography, azure-core, SecretStorage, pyopenssl, paramiko, msrest, jsonschema, google-api-core, flask-cors, azure-mgmt-core, adal, opencensus, ndg-httpsclient, msrestazure, msal, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-network, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, msal-extensions, azureml-train-restclients-hyperdrive, azure-graphrbac, azureml-core, azure-identity, opencensus-ext-azure, azureml-telemetry, azureml-pipeline-core, azureml-dataprep, azureml-train-core, azureml-inference-server-http, azureml-dataset-runtime, azureml-automl-core, azureml-train-automl-client, azureml-defaults, azureml-pipeline-steps, azureml-pipeline, azureml-sdk\n2024-10-09T18:19:03:   Attempting uninstall: numpy\n2024-10-09T18:19:03:     Found existing installation: numpy 1.26.4\n2024-10-09T18:19:03:     Uninstalling numpy-1.26.4:\n2024-10-09T18:19:03:       Successfully uninstalled numpy-1.26.4\n2024-10-09T18:19:03: Successfully installed Jinja2-3.1.4 MarkupSafe-3.0.1 PyJWT-2.9.0 PySocks-1.7.1 SecretStorage-3.3.3 adal-1.2.7 annotated-types-0.7.0 applicationinsights-0.11.10 argcomplete-3.5.1 attrs-24.2.0 azure-common-1.1.28 azure-core-1.31.0 azure-graphrbac-0.61.1 azure-identity-1.19.0 azure-mgmt-authorization-4.0.0 azure-mgmt-containerregistry-10.3.0 azure-mgmt-core-1.4.0 azure-mgmt-keyvault-10.3.1 azure-mgmt-network-26.0.0 azure-mgmt-resource-23.1.1 azure-mgmt-storage-21.2.1 azureml-automl-core-1.57.0 azureml-core-1.57.0.post3 azureml-dataprep-5.1.6 azureml-dataprep-native-41.0.0 azureml-dataprep-rslex-2.22.4 azureml-dataset-runtime-1.57.0 azureml-defaults-1.57.0.post1 azureml-inference-server-http-1.3.3 azureml-pipeline-1.57.0 azureml-pipeline-core-1.57.0 azureml-pipeline-steps-1.57.0 azureml-sdk-1.57.0 azureml-telemetry-1.57.0 azureml-train-automl-client-1.57.0 azureml-train-core-1.57.0 azureml-train-restclients-hyperdrive-1.57.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.2.0 blinker-1.8.2 cachetools-5.5.0 certifi-2024.8.30 cffi-1.17.1 charset-normalizer-3.4.0 click-8.1.7 cloudpickle-2.2.1 contextlib2-21.6.0 cryptography-43.0.1 docker-7.1.0 flask-2.3.2 flask-cors-5.0.0 fusepy-3.0.1 google-api-core-2.21.0 google-auth-2.35.0 googleapis-common-protos-1.65.0 gunicorn-22.0.0 humanfriendly-10.0 idna-3.10 inference-schema-1.8 isodate-0.7.2 itsdangerous-2.2.0 jeepney-0.8.0 jmespath-1.0.1 jsonpickle-3.3.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 knack-0.11.0 msal-1.31.0 msal-extensions-1.2.0 msrest-0.7.1 msrestazure-0.6.4.post1 ndg-httpsclient-0.5.1 numpy-1.23.5 oauthlib-3.2.2 opencensus-0.11.4 opencensus-context-0.1.3 opencensus-ext-azure-1.1.13 paramiko-3.5.0 pathspec-0.12.1 pkginfo-1.11.1 portalocker-2.10.1 proto-plus-1.24.0 protobuf-5.28.2 pyarrow-17.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pycparser-2.22 pydantic-2.7.4 pydantic-core-2.18.4 pydantic-settings-2.5.2 pynacl-1.5.0 pyopenssl-24.2.1 python-dotenv-1.0.1 pyyaml-6.0.2 referencing-0.35.1 requests-2.32.3 requests-oauthlib-2.0.0 rpds-py-0.20.0 rsa-4.9 tabulate-0.9.0 urllib3-2.2.3 werkzeug-3.0.4 wrapt-1.16.0\n\n2024-10-09T18:19:03: done\n2024-10-09T18:19:03: #\n2024-10-09T18:19:03: # To activate this environment, use\n2024-10-09T18:19:03: #\n2024-10-09T18:19:03: #     $ conda activate /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7\n2024-10-09T18:19:03: #\n2024-10-09T18:19:03: # To deactivate an active environment, use\n2024-10-09T18:19:03: #\n2024-10-09T18:19:03: #     $ conda deactivate\n\n2024-10-09T18:19:59: Removing intermediate container ae9e1645328d\n2024-10-09T18:19:59:  ---> 16433dfd8664\n2024-10-09T18:19:59: Step 9/17 : ENV PATH /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7/bin:$PATH\n2024-10-09T18:19:59:  ---> Running in 0c4644c5bd9e\n2024-10-09T18:20:02: Removing intermediate container 0c4644c5bd9e\n2024-10-09T18:20:02:  ---> 0f033c7faac4\n2024-10-09T18:20:02: Step 10/17 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7\n2024-10-09T18:20:02:  ---> Running in 792c6b77d7be\n2024-10-09T18:20:05: Removing intermediate container 792c6b77d7be\n2024-10-09T18:20:05:  ---> 6e4b735d683a\n2024-10-09T18:20:05: Step 11/17 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7/lib:$LD_LIBRARY_PATH\n2024-10-09T18:20:06:  ---> Running in 5e7eba34df53\n2024-10-09T18:20:09: Removing intermediate container 5e7eba34df53\n2024-10-09T18:20:09:  ---> ff1af352c49e\n2024-10-09T18:20:09: Step 12/17 : ENV CONDA_DEFAULT_ENV=azureml_3c6c21958ca581595a5556ee6f7a6ed7 CONDA_PREFIX=/azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7\n2024-10-09T18:20:09:  ---> Running in 44ea31856dc2\n2024-10-09T18:20:12: Removing intermediate container 44ea31856dc2\n2024-10-09T18:20:12:  ---> 9dab11890b29\n2024-10-09T18:20:12: Step 13/17 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n2024-10-09T18:20:15:  ---> a27b8ef8cb8d\n2024-10-09T18:20:15: Step 14/17 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n2024-10-09T18:20:15:  ---> Running in 3fc2fb8254da\n2024-10-09T18:20:19: Removing intermediate container 3fc2fb8254da\n2024-10-09T18:20:19:  ---> f8866ab4e144\n2024-10-09T18:20:19: Step 15/17 : RUN rm -rf azureml-environment-setup\n2024-10-09T18:20:19:  ---> Running in c80a6555153e\n2024-10-09T18:20:23: Removing intermediate container c80a6555153e\n2024-10-09T18:20:23:  ---> 163d8775f12c\n2024-10-09T18:20:23: Step 16/17 : ENV AZUREML_ENVIRONMENT_IMAGE True\n2024-10-09T18:20:23:  ---> Running in 146c48ba65c5\n2024-10-09T18:20:26: Removing intermediate container 146c48ba65c5\n2024-10-09T18:20:26:  ---> b064861c5de8\n2024-10-09T18:20:26: Step 17/17 : CMD [\"bash\"]\n2024-10-09T18:20:26:  ---> Running in 9b2e351fabbf\n2024-10-09T18:20:30: Removing intermediate container 9b2e351fabbf\n2024-10-09T18:20:30:  ---> 1d18c31750d1\n2024-10-09T18:20:30: Successfully built 1d18c31750d1\n2024-10-09T18:20:30: Successfully tagged 18c17ad430534e1c9f2569c80eb22a73.azurecr.io/azureml/azureml_ef40939cb933183bffcbfd8160e11fcf:latest\n2024-10-09T18:20:30: Successfully tagged 18c17ad430534e1c9f2569c80eb22a73.azurecr.io/azureml/azureml_ef40939cb933183bffcbfd8160e11fcf:1\n\n\n2024-10-09T18:20:30: Logging into Docker registry: 18c17ad430534e1c9f2569c80eb22a73.azurecr.io\n2024-10-09T18:20:30: WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n2024-10-09T18:20:30: WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n2024-10-09T18:20:30: Configure a credential helper to remove this warning. See\n2024-10-09T18:20:30: https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\n2024-10-09T18:20:30: Login Succeeded\n\n\n2024-10-09T18:20:30: Found send_dependencies.py at: /tmp/tmp7gfy4ja9/azureml-environment-setup/send_dependencies.py\n2024-10-09T18:20:30: Using default tag: latest\n2024-10-09T18:20:30: The push refers to repository [18c17ad430534e1c9f2569c80eb22a73.azurecr.io/azureml/azureml_ef40939cb933183bffcbfd8160e11fcf]\n2024-10-09T18:20:30: a2d8716f373f: Preparing\n2024-10-09T18:20:30: 1729d3d14141: Preparing\n2024-10-09T18:20:30: e79e74ee4f9f: Preparing\n2024-10-09T18:20:30: 4ad3f24c1407: Preparing\n2024-10-09T18:20:30: 217a0c779cc9: Preparing\n2024-10-09T18:20:30: 7516dd79ee66: Preparing\n2024-10-09T18:20:30: fa7914530e1a: Preparing\n2024-10-09T18:20:30: 7782b0735218: Preparing\n2024-10-09T18:20:30: 26e70302eec3: Preparing\n2024-10-09T18:20:30: 86e8dd9677e1: Preparing\n2024-10-09T18:20:30: 10b9700626a3: Preparing\n2024-10-09T18:20:30: 841b46be6e00: Preparing\n2024-10-09T18:20:30: 70eb0293fee9: Preparing\n2024-10-09T18:20:30: 59bc9b8312ea: Preparing\n2024-10-09T18:20:30: 0a03b0e692d6: Preparing\n2024-10-09T18:20:30: 3ec3ded77c0c: Preparing\n2024-10-09T18:20:30: 7516dd79ee66: Waiting\n2024-10-09T18:20:30: fa7914530e1a: Waiting\n2024-10-09T18:20:30: 7782b0735218: Waiting\n2024-10-09T18:20:30: 26e70302eec3: Waiting\n2024-10-09T18:20:30: 86e8dd9677e1: Waiting\n2024-10-09T18:20:30: 10b9700626a3: Waiting\n2024-10-09T18:20:30: 841b46be6e00: Waiting\n2024-10-09T18:20:30: 70eb0293fee9: Waiting\n2024-10-09T18:20:30: 59bc9b8312ea: Waiting\n2024-10-09T18:20:30: 0a03b0e692d6: Waiting\n2024-10-09T18:20:30: 3ec3ded77c0c: Waiting\n2024-10-09T18:20:30: 4ad3f24c1407: Pushed\n2024-10-09T18:20:30: a2d8716f373f: Pushed\n2024-10-09T18:20:30: 1729d3d14141: Pushed\n2024-10-09T18:20:31: 7516dd79ee66: Pushed\n2024-10-09T18:20:31: fa7914530e1a: Pushed\n2024-10-09T18:20:31: 7782b0735218: Pushed\n2024-10-09T18:20:33: 86e8dd9677e1: Pushed\n2024-10-09T18:20:34: 841b46be6e00: Pushed\n2024-10-09T18:20:34: 26e70302eec3: Pushed\n2024-10-09T18:20:34: 217a0c779cc9: Pushed\n2024-10-09T18:20:35: 70eb0293fee9: Pushed\n2024-10-09T18:20:35: 59bc9b8312ea: Pushed\n2024-10-09T18:20:39: 3ec3ded77c0c: Pushed\n2024-10-09T18:20:46: 10b9700626a3: Pushed\n2024-10-09T18:20:56: 0a03b0e692d6: Pushed\n2024-10-09T18:21:54: e79e74ee4f9f: Pushed\n2024-10-09T18:21:55: latest: digest: sha256:e39be7955de8e53fbacd4e394ca960137f28afcfdef02852e615e36c67aa3ea9 size: 3679\n\n\n2024-10-09T18:21:56: Attempting to run dependencies script\n\n\n2024-10-09T18:21:59: Report materialized dependencies for the environment\n2024-10-09T18:21:59: Reading environment context\n2024-10-09T18:21:59: Exporting conda environment\n2024-10-09T18:21:59: Sending request with materialized conda environment details\n2024-10-09T18:21:59: Successfully sent materialized environment dependencies\n\n\n2024-10-09T18:21:59: 68369318852c97c4a2c30ed3bb81df8d898b9bc4f3b5abc4eab3692a9c45fcf2\n\n\n2024-10-09T18:21:59: The push refers to repository [18c17ad430534e1c9f2569c80eb22a73.azurecr.io/azureml/azureml_ef40939cb933183bffcbfd8160e11fcf]\n2024-10-09T18:21:59: a2d8716f373f: Preparing\n2024-10-09T18:21:59: 1729d3d14141: Preparing\n2024-10-09T18:21:59: e79e74ee4f9f: Preparing\n2024-10-09T18:21:59: 4ad3f24c1407: Preparing\n2024-10-09T18:21:59: 217a0c779cc9: Preparing\n2024-10-09T18:21:59: 7516dd79ee66: Preparing\n2024-10-09T18:21:59: fa7914530e1a: Preparing\n2024-10-09T18:21:59: 7782b0735218: Preparing\n2024-10-09T18:21:59: 26e70302eec3: Preparing\n2024-10-09T18:21:59: 86e8dd9677e1: Preparing\n2024-10-09T18:21:59: 10b9700626a3: Preparing\n2024-10-09T18:21:59: 841b46be6e00: Preparing\n2024-10-09T18:21:59: 70eb0293fee9: Preparing\n2024-10-09T18:21:59: 59bc9b8312ea: Preparing\n2024-10-09T18:21:59: 0a03b0e692d6: Preparing\n2024-10-09T18:21:59: 3ec3ded77c0c: Preparing\n2024-10-09T18:21:59: 7516dd79ee66: Waiting\n2024-10-09T18:21:59: fa7914530e1a: Waiting\n2024-10-09T18:21:59: 7782b0735218: Waiting\n2024-10-09T18:21:59: 26e70302eec3: Waiting\n2024-10-09T18:21:59: 86e8dd9677e1: Waiting\n2024-10-09T18:21:59: 10b9700626a3: Waiting\n2024-10-09T18:21:59: 841b46be6e00: Waiting\n2024-10-09T18:21:59: 59bc9b8312ea: Waiting\n2024-10-09T18:21:59: 0a03b0e692d6: Waiting\n2024-10-09T18:21:59: 3ec3ded77c0c: Waiting\n2024-10-09T18:21:59: 70eb0293fee9: Waiting\n2024-10-09T18:21:59: a2d8716f373f: Layer already exists\n2024-10-09T18:21:59: 4ad3f24c1407: Layer already exists\n2024-10-09T18:21:59: 217a0c779cc9: Layer already exists\n2024-10-09T18:21:59: 1729d3d14141: Layer already exists\n2024-10-09T18:21:59: e79e74ee4f9f: Layer already exists\n2024-10-09T18:21:59: fa7914530e1a: Layer already exists\n2024-10-09T18:21:59: 7782b0735218: Layer already exists\n2024-10-09T18:21:59: 7516dd79ee66: Layer already exists\n2024-10-09T18:21:59: 10b9700626a3: Layer already exists\n2024-10-09T18:21:59: 26e70302eec3: Layer already exists\n2024-10-09T18:21:59: 86e8dd9677e1: Layer already exists\n2024-10-09T18:21:59: 841b46be6e00: Layer already exists\n2024-10-09T18:21:59: 70eb0293fee9: Layer already exists\n2024-10-09T18:21:59: 0a03b0e692d6: Layer already exists\n2024-10-09T18:21:59: 59bc9b8312ea: Layer already exists\n2024-10-09T18:21:59: 3ec3ded77c0c: Layer already exists\n2024-10-09T18:22:04: 1: digest: sha256:e39be7955de8e53fbacd4e394ca960137f28afcfdef02852e615e36c67aa3ea9 size: 3679\n\n\n2024-10-09T18:22:04: Attempting to run dependencies script\n\n\n2024-10-09T18:22:07: Report materialized dependencies for the environment\n2024-10-09T18:22:07: Reading environment context\n2024-10-09T18:22:07: Exporting conda environment\n2024-10-09T18:22:07: Sending request with materialized conda environment details\n2024-10-09T18:22:07: Successfully sent materialized environment dependencies\n\n\n2024-10-09T18:22:08: a3e6c94b60ba0b309ebbc065dddc529f578d71106f3d67a0860195a789a08f38\n\n\n2024-10-09T18:22:08: Deleting 18c17ad430534e1c9f2569c80eb22a73.azurecr.io/azureml/azureml_ef40939cb933183bffcbfd8160e11fcf from local machine\n2024-10-09T18:22:08: Error response from daemon: page not found\n\n\n2024-10-09T18:22:08: Logging out of Docker registry: 18c17ad430534e1c9f2569c80eb22a73.azurecr.io\n2024-10-09T18:22:08: Removing login credentials for https://index.docker.io/v1/\n\n\n2024-10-09T18:22:08: Logging out of Docker registry: 18c17ad430534e1c9f2569c80eb22a73.azurecr.io\n2024-10-09T18:22:08: Removing login credentials for https://index.docker.io/v1/\n\n\n\nStreaming user_logs/std_log.txt\n===============================\n\nLoading Data...\n{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe'}\n{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe', 'activityApp': 'TabularDataset'}\n{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe', 'activityApp': 'TabularDataset', 'runId': 'cbml-train-finance_1728497564_e1e3bcaf'}\n{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe', 'activityApp': 'TabularDataset', 'runId': 'cbml-train-finance_1728497564_e1e3bcaf', 'run_id': 'cbml-train-finance_1728497564_e1e3bcaf'}\nTraining a logistic regression model\n/azureml-envs/azureml_3c6c21958ca581595a5556ee6f7a6ed7/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\nAccuracy: 0.895\nfinance_training.py:42: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  run.log('Accuracy', np.float(acc))\nAUC: 0.9650756650710969\nfinance_training.py:48: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  run.log('AUC', np.float(auc))\nCleaning up all outstanding Run operations, waiting 300.0 seconds\n1 items cleaning up...\nCleanup took 0.06013941764831543 seconds\n\nExecution Summary\n=================\nRunId: cbml-train-finance_1728497564_e1e3bcaf\nWeb View: https://ml.azure.com/runs/cbml-train-finance_1728497564_e1e3bcaf?wsid=/subscriptions/805e2807-b34c-423a-83fb-6c6c635d5b7a/resourcegroups/rg-contosobank-lf66db13b49ae47f691/workspaces/mlw-cb-lf66db13b49ae47f691&tid=d83a6143-104d-46a7-987d-230c352019f1\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 72,
          "data": {
            "text/plain": "{'runId': 'cbml-train-finance_1728497564_e1e3bcaf',\n 'target': 'cb-aml-cluster',\n 'status': 'Completed',\n 'startTimeUtc': '2024-10-09T18:25:40.806952Z',\n 'endTimeUtc': '2024-10-09T18:27:30.195795Z',\n 'services': {},\n 'properties': {'_azureml.ComputeTargetType': 'amlctrain',\n  '_azureml.ClusterName': 'cb-aml-cluster',\n  'ContentSnapshotId': '02eb6685-2de3-4a8c-b736-17a5553187ea',\n  'ProcessInfoFile': 'azureml-logs/process_info.json',\n  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n 'inputDatasets': [{'dataset': {'id': '1704185d-8423-49d9-a227-147e270d3daf'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}],\n 'outputDatasets': [],\n 'runDefinition': {'script': 'finance_training.py',\n  'command': '',\n  'useAbsolutePath': False,\n  'arguments': ['--input-data', 'DatasetConsumptionConfig:training_data'],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'cb-aml-cluster',\n  'dataReferences': {},\n  'data': {'training_data': {'dataLocation': {'dataset': {'id': '1704185d-8423-49d9-a227-147e270d3daf',\n      'name': 'finance1_ds',\n      'version': '1'},\n     'dataPath': None,\n     'uri': None,\n     'type': None},\n    'mechanism': 'Direct',\n    'environmentVariableName': 'training_data',\n    'pathOnCompute': None,\n    'overwrite': False,\n    'options': None}},\n  'outputData': {},\n  'datacaches': [],\n  'jobName': None,\n  'maxRunDurationSeconds': 2592000,\n  'nodeCount': 1,\n  'instanceTypes': [],\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'financial-experiment-env',\n   'version': '1',\n   'assetId': 'azureml://locations/westeurope/workspaces/18c17ad4-3053-4e1c-9f25-69c80eb22a73/environments/financial-experiment-env/versions/1',\n   'autoRebuild': True,\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'name': 'project_environment',\n     'dependencies': ['python=3.9.12',\n      {'pip': ['azureml-sdk', 'pyarrow', 'azureml-defaults']},\n      'scikit-learn',\n      'ipykernel',\n      'matplotlib',\n      'pandas',\n      'pip'],\n     'channels': ['anaconda', 'conda-forge']},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20240908.v1',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': False,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'enableMLflowTracking': True,\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': None},\n  'aiSuperComputer': {'instanceType': 'D2',\n   'imageVersion': None,\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None,\n   'virtualClusterArmId': None,\n   'tensorboardLogDirectory': None,\n   'sshPublicKey': None,\n   'sshPublicKeys': None,\n   'enableAzmlInt': True,\n   'priority': 'Medium',\n   'slaTier': 'Standard',\n   'userAlias': None},\n  'kubernetesCompute': {'instanceType': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': False,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []},\n  'environmentVariables': {},\n  'applicationEndpoints': {},\n  'parameters': []},\n 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://mlwcblf6storagea12fca3b2.blob.core.windows.net/azureml/ExperimentRun/dcid.cbml-train-finance_1728497564_e1e3bcaf/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=khCeBBLxh9XA5kE5DRJYWPckuL2ONrDm5XErj5AWAqA%3D&skoid=7705553f-4844-4ad5-bcb9-87ea042f26c9&sktid=d83a6143-104d-46a7-987d-230c352019f1&skt=2024-10-09T18%3A02%3A52Z&ske=2024-10-11T18%3A12%3A52Z&sks=b&skv=2019-07-07&st=2024-10-09T18%3A13%3A36Z&se=2024-10-10T02%3A23%3A36Z&sp=r',\n  'logs/azureml/dataprep/0/rslex.log.2024-10-09-18': 'https://mlwcblf6storagea12fca3b2.blob.core.windows.net/azureml/ExperimentRun/dcid.cbml-train-finance_1728497564_e1e3bcaf/logs/azureml/dataprep/0/rslex.log.2024-10-09-18?sv=2019-07-07&sr=b&sig=uYuNCmWaqQVHt%2FzxbRYjroW7%2Fv2sk1oQ%2FLrx0wJSpSY%3D&skoid=7705553f-4844-4ad5-bcb9-87ea042f26c9&sktid=d83a6143-104d-46a7-987d-230c352019f1&skt=2024-10-09T18%3A02%3A52Z&ske=2024-10-11T18%3A12%3A52Z&sks=b&skv=2019-07-07&st=2024-10-09T18%3A17%3A37Z&se=2024-10-10T02%3A27%3A37Z&sp=r',\n  'user_logs/std_log.txt': 'https://mlwcblf6storagea12fca3b2.blob.core.windows.net/azureml/ExperimentRun/dcid.cbml-train-finance_1728497564_e1e3bcaf/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=u9RamlJx3osNrlQD5lwsX1sb3%2BN61SD9EH1ejKPXi5w%3D&skoid=7705553f-4844-4ad5-bcb9-87ea042f26c9&sktid=d83a6143-104d-46a7-987d-230c352019f1&skt=2024-10-09T18%3A02%3A52Z&ske=2024-10-11T18%3A12%3A52Z&sks=b&skv=2019-07-07&st=2024-10-09T18%3A17%3A38Z&se=2024-10-10T02%3A27%3A38Z&sp=r',\n  'system_logs/cs_capability/cs-capability.log': 'https://mlwcblf6storagea12fca3b2.blob.core.windows.net/azureml/ExperimentRun/dcid.cbml-train-finance_1728497564_e1e3bcaf/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=M6aBMR6%2BhCbtTeL758yilqzHsKBfPS5f3WKPes%2BRoeQ%3D&skoid=7705553f-4844-4ad5-bcb9-87ea042f26c9&sktid=d83a6143-104d-46a7-987d-230c352019f1&skt=2024-10-09T18%3A02%3A52Z&ske=2024-10-11T18%3A12%3A52Z&sks=b&skv=2019-07-07&st=2024-10-09T18%3A17%3A38Z&se=2024-10-10T02%3A27%3A38Z&sp=r',\n  'system_logs/hosttools_capability/hosttools-capability.log': 'https://mlwcblf6storagea12fca3b2.blob.core.windows.net/azureml/ExperimentRun/dcid.cbml-train-finance_1728497564_e1e3bcaf/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=oQqYaI7nsLnnaFgj8Z9dALWSUG%2FCpzseV%2BxZ9NsOaY0%3D&skoid=7705553f-4844-4ad5-bcb9-87ea042f26c9&sktid=d83a6143-104d-46a7-987d-230c352019f1&skt=2024-10-09T18%3A02%3A52Z&ske=2024-10-11T18%3A12%3A52Z&sks=b&skv=2019-07-07&st=2024-10-09T18%3A17%3A38Z&se=2024-10-10T02%3A27%3A38Z&sp=r',\n  'system_logs/lifecycler/execution-wrapper.log': 'https://mlwcblf6storagea12fca3b2.blob.core.windows.net/azureml/ExperimentRun/dcid.cbml-train-finance_1728497564_e1e3bcaf/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=w2ol%2FBafs70zg92%2FdXyBnDlBcmcEMURvbhorvPTsGwY%3D&skoid=7705553f-4844-4ad5-bcb9-87ea042f26c9&sktid=d83a6143-104d-46a7-987d-230c352019f1&skt=2024-10-09T18%3A02%3A52Z&ske=2024-10-11T18%3A12%3A52Z&sks=b&skv=2019-07-07&st=2024-10-09T18%3A17%3A38Z&se=2024-10-10T02%3A27%3A38Z&sp=r',\n  'system_logs/lifecycler/lifecycler.log': 'https://mlwcblf6storagea12fca3b2.blob.core.windows.net/azureml/ExperimentRun/dcid.cbml-train-finance_1728497564_e1e3bcaf/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=sbRubsGCTGr8LBAWI%2Fe0ZrWXeQ0pyA0Vwn8U74nGvtQ%3D&skoid=7705553f-4844-4ad5-bcb9-87ea042f26c9&sktid=d83a6143-104d-46a7-987d-230c352019f1&skt=2024-10-09T18%3A02%3A52Z&ske=2024-10-11T18%3A12%3A52Z&sks=b&skv=2019-07-07&st=2024-10-09T18%3A17%3A38Z&se=2024-10-10T02%3A27%3A38Z&sp=r',\n  'system_logs/metrics_capability/metrics-capability.log': 'https://mlwcblf6storagea12fca3b2.blob.core.windows.net/azureml/ExperimentRun/dcid.cbml-train-finance_1728497564_e1e3bcaf/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=Np9pxd4Rf9PgjKWRTqXsUS1ch4MQLQeZ8tLHVeCcQ8A%3D&skoid=7705553f-4844-4ad5-bcb9-87ea042f26c9&sktid=d83a6143-104d-46a7-987d-230c352019f1&skt=2024-10-09T18%3A02%3A52Z&ske=2024-10-11T18%3A12%3A52Z&sks=b&skv=2019-07-07&st=2024-10-09T18%3A17%3A38Z&se=2024-10-10T02%3A27%3A38Z&sp=r',\n  'system_logs/snapshot_capability/snapshot-capability.log': 'https://mlwcblf6storagea12fca3b2.blob.core.windows.net/azureml/ExperimentRun/dcid.cbml-train-finance_1728497564_e1e3bcaf/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=mijLBvz%2F%2FoTI90waGy2YxGLISKM5Z7VVtZbuVGYXck0%3D&skoid=7705553f-4844-4ad5-bcb9-87ea042f26c9&sktid=d83a6143-104d-46a7-987d-230c352019f1&skt=2024-10-09T18%3A02%3A52Z&ske=2024-10-11T18%3A12%3A52Z&sks=b&skv=2019-07-07&st=2024-10-09T18%3A17%3A38Z&se=2024-10-10T02%3A27%3A38Z&sp=r'},\n 'submittedBy': 'AOAI TFS 009067'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 72,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728498460251
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the experiment has finished, you can get the metrics and files generated by the experiment run. This time, the files will include logs for building the image and managing the compute."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get logged metrics\n",
        "metrics = run.get_metrics()\n",
        "for key in metrics.keys():\n",
        "        print(key, metrics.get(key))\n",
        "print('\\n')\n",
        "for file in run.get_file_names():\n",
        "    print(file)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "AUC 0.9650756650710969\nAccuracy 0.895\n\n\nazureml-logs/20_image_build_log.txt\nlogs/azureml/dataprep/0/rslex.log.2024-10-09-18\noutputs/finance_model.pkl\nsystem_logs/cs_capability/cs-capability.log\nsystem_logs/hosttools_capability/hosttools-capability.log\nsystem_logs/lifecycler/execution-wrapper.log\nsystem_logs/lifecycler/lifecycler.log\nsystem_logs/metrics_capability/metrics-capability.log\nsystem_logs/snapshot_capability/snapshot-capability.log\nuser_logs/std_log.txt\n"
        }
      ],
      "execution_count": 73,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728498705647
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can register the model that was trained by the experiment."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "# Register the model\n",
        "run.register_model(model_path='outputs/finance_model.pkl', model_name='finance_model',\n",
        "                   tags={'Training context':'Compute cluster'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "# List registered models\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "finance_model version: 1\n\t Training context : Compute cluster\n\t AUC : 0.9650756650710969\n\t Accuracy : 0.895\n\n\n"
        }
      ],
      "execution_count": 74,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728498768783
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy the model as a web service\n",
        "You have trained and registered a machine learning model that classifies customers based on the likelihood of them taking loans. This model could be used in a production environment where the banks wants to find out who are their potential customers ready to take a loan. To support this scenario, you will deploy the model as a web service."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "model = Model(ws, 'finance_model', version = 1)\n",
        "print(model.name, 'version', model.version)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "finance_model version 1\n"
        }
      ],
      "execution_count": 75,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728498811489
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_name = 'finance_service'\n",
        "\n",
        "# Create a folder for the web service files\n",
        "experiment_folder = './' + folder_name\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print(folder_name, 'folder created.')\n",
        "\n",
        "# Set path for scoring script\n",
        "script_file = os.path.join(experiment_folder,\"score_finance.py\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "finance_service folder created.\n"
        }
      ],
      "execution_count": 76,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728498842575
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The web service where we deploy the model will need some Python code to load the input data, get the model from the workspace, and generate and return predictions. We'll save this code in an entry script (often called a scoring script) that will be deployed to the web service:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_file\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "from azureml.core.model import Model\n",
        "\n",
        "# Called when the service is loaded\n",
        "def init():\n",
        "    global model\n",
        "    # Get the path to the deployed model file and load it\n",
        "    model_path = Model.get_model_path('finance_model')\n",
        "    print(model_path)\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "# Called when a request is received\n",
        "def run(raw_data):\n",
        "    # Get the input data as a numpy array\n",
        "    data = np.array(json.loads(raw_data)['data'])\n",
        "    # Get a prediction from the model\n",
        "    predictions = model.predict(data)\n",
        "    return json.dumps({\"result\": predictions.tolist()})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing ./finance_service/score_finance.py\n"
        }
      ],
      "execution_count": 77,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment will take some time as it first runs a process to create a container image, and then runs a process to create a web service based on the image. When deployment has completed successfully, you'll see a status of Healthy."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "# Configure the scoring environment\n",
        "inference_config = InferenceConfig(entry_script=script_file,\n",
        "                                   environment=registered_env)\n",
        "\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
        "\n",
        "service_name = \"finance-service2\"\n",
        "\n",
        "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
        "\n",
        "service.wait_for_deployment(True)\n",
        "print(service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_4517/4076493211.py:12: FutureWarning: azureml.core.model:\nTo leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \nplease refer to respective documentations \nhttps://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\nhttps://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \nFor more information on migration, see https://aka.ms/acimoemigration \nTo disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n  service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2024-10-09 18:36:42+00:00 Creating Container Registry if not exists.\n2024-10-09 18:36:46+00:00 Use the existing image.\n2024-10-09 18:36:47+00:00 Generating deployment configuration.\n2024-10-09 18:36:48+00:00 Submitting deployment to compute.\n2024-10-09 18:36:53+00:00 Checking the status of deployment finance-service2..\n2024-10-09 18:38:51+00:00 Checking the status of inference endpoint finance-service2.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\nHealthy\n"
        }
      ],
      "execution_count": 78,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728499134039
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for webservice_name in ws.webservices:\n",
        "    print(webservice_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "finance-service2\n"
        }
      ],
      "execution_count": 80,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728499161024
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the web service\n",
        "With the service deployed, now you can consume it from a client application."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = service.scoring_uri\n",
        "print(endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "http://49280218-4dd4-40e1-a462-b50d359aed28.westeurope.azurecontainer.io/score\n"
        }
      ],
      "execution_count": 81,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728499184598
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "x_new = [[38,16,500,1,6.9,3,0,0,0,0,0],\n",
        "         [22,1,100,2,1.2,1,0,0,0,0,0]]\n",
        "\n",
        "\n",
        "# Convert the array to a serializable list in a JSON document\n",
        "input_json = json.dumps({\"data\": x_new})\n",
        "\n",
        "# Set the content type\n",
        "headers = { 'Content-Type':'application/json' }\n",
        "\n",
        "predictions = requests.post(endpoint, input_json, headers = headers)\n",
        "predicted_classes = json.loads(predictions.json())"
      ],
      "outputs": [],
      "execution_count": 82,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728499220161
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(x_new)):\n",
        "    if predicted_classes['result'][i] == 1.0 : \n",
        "        customer_class = 'an Asset Customer'\n",
        "    else :\n",
        "        customer_class = 'a liability Customer'\n",
        "    print (\"Customer Type {}\".format(x_new[i]), \"has predicted score\", predicted_classes['result'][i], \"therefore it is\", customer_class )\n",
        "    "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Customer Type [38, 16, 500, 1, 6.9, 3, 0, 0, 0, 0, 0] has predicted score 1.0 therefore it is an Asset Customer\nCustomer Type [22, 1, 100, 2, 1.2, 1, 0, 0, 0, 0, 0] has predicted score 0.0 therefore it is a liability Customer\n"
        }
      ],
      "execution_count": 83,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728499230663
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Integrating Text Analytics with Your Model:\n",
        "Use Text Analytics API to extract sentiments and key phrases from customer data before feeding it to your model.\n",
        "Install Azure AI Services SDK"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install azure-ai-textanalytics\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting azure-ai-textanalytics\n  Downloading azure_ai_textanalytics-5.3.0-py3-none-any.whl.metadata (82 kB)\nRequirement already satisfied: azure-core<2.0.0,>=1.24.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (1.31.0)\nRequirement already satisfied: azure-common~=1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (1.1.28)\nRequirement already satisfied: isodate<1.0.0,>=0.6.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (0.6.1)\nRequirement already satisfied: typing-extensions>=4.0.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (4.12.2)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.32.3)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2024.8.30)\nDownloading azure_ai_textanalytics-5.3.0-py3-none-any.whl (298 kB)\nInstalling collected packages: azure-ai-textanalytics\nSuccessfully installed azure-ai-textanalytics-5.3.0\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 84,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728500190598
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install azure-ai-textanalytics"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.textanalytics import TextAnalyticsClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "\n",
        "# Authenticate Text Analytics client\n",
        "credential = AzureKeyCredential('be51ab75a59f4e8288c3c59ce9c4c4b1')\n",
        "text_analytics_client = TextAnalyticsClient(endpoint='https://cbsb-text-al.cognitiveservices.azure.com/', credential=credential)\n",
        "\n",
        "# Analyze customer feedback\n",
        "feedback = [\"The loan process taking long time to get approval\"]\n",
        "response = text_analytics_client.analyze_sentiment(feedback)\n",
        "for document in response:\n",
        "    print(f\"Sentiment: {document.sentiment}\")\n",
        "\n",
        "# Pass sentiment and feedback to your AML model endpoint\n",
        "import requests\n",
        "model_endpoint = \"http://49280218-4dd4-40e1-a462-b50d359aed28.westeurope.azurecontainer.io/score\"\n",
        "data = {\n",
        "    'feedback': document.sentiment, \n",
        "    'text': document.text\n",
        "}\n",
        "response = requests.post(model_endpoint, json=data)\n",
        "print(response.json())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sentiment: negative\n"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'AnalyzeSentimentResult' object has no attribute 'text'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model_endpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://49280218-4dd4-40e1-a462-b50d359aed28.westeurope.azurecontainer.io/score\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeedback\u001b[39m\u001b[38;5;124m'\u001b[39m: document\u001b[38;5;241m.\u001b[39msentiment, \n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mdocument\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m     20\u001b[0m }\n\u001b[1;32m     21\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(model_endpoint, json\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mjson())\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'AnalyzeSentimentResult' object has no attribute 'text'"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728502218010
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install azure-search-documents\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting azure-search-documents\n  Downloading azure_search_documents-11.5.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: azure-core>=1.28.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-search-documents) (1.31.0)\nRequirement already satisfied: azure-common>=1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-search-documents) (1.1.28)\nRequirement already satisfied: isodate>=0.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-search-documents) (0.6.1)\nRequirement already satisfied: typing-extensions>=4.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-search-documents) (4.12.2)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core>=1.28.0->azure-search-documents) (2.32.3)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core>=1.28.0->azure-search-documents) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-search-documents) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-search-documents) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-search-documents) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-search-documents) (2024.8.30)\nDownloading azure_search_documents-11.5.1-py3-none-any.whl (297 kB)\nInstalling collected packages: azure-search-documents\nSuccessfully installed azure-search-documents-11.5.1\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728504040112
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the index "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents.indexes import SearchIndexClient\n",
        "from azure.search.documents.indexes.models import (\n",
        "    ComplexField, SearchIndex, SearchFieldDataType, SimpleField\n",
        ")\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "\n",
        "# Replace with your own values\n",
        "endpoint = \"https://<your-search-service>.search.windows.net\"\n",
        "api_key = \"UKLhj386eShzFyTiOkQUZ39naZPoeGbEFOMuly7RGAAzSeDk8VJQ\"\n",
        "\n",
        "# Create a client\n",
        "client = SearchIndexClient(endpoint=endpoint, credential=AzureKeyCredential(api_key))\n",
        "\n",
        "# Define the index schema\n",
        "index_name = \"campaign-results-index\"\n",
        "fields = [\n",
        "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
        "    SimpleField(name=\"customer_name\", type=SearchFieldDataType.String, searchable=True),\n",
        "    SimpleField(name=\"loan_eligibility\", type=SearchFieldDataType.String, searchable=True),\n",
        "    SimpleField(name=\"segment\", type=SearchFieldDataType.String, searchable=True),\n",
        "    SimpleField(name=\"campaign_conversion_rate\", type=SearchFieldDataType.Double)\n",
        "]\n",
        "\n",
        "index = SearchIndex(name=index_name, fields=fields)\n",
        "\n",
        "# Create the index in the search service\n",
        "client.create_index(index)\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "<azure.search.documents.indexes.models._index.SearchIndex at 0x7f53728652d0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728504046766
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Data for Indexing\n",
        "Data for Azure AI Search needs to be in JSON format, with fields like campaign performance, segment details, customer profiles, etc"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = [\n",
        "    {\n",
        "        \"id\": \"1\",\n",
        "        \"customer_name\": \"John Doe\",\n",
        "        \"loan_eligibility\": \"Yes\",\n",
        "        \"segment\": \"High Value\",\n",
        "        \"campaign_conversion_rate\": 15.3\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"2\",\n",
        "        \"customer_name\": \"Jane Smith\",\n",
        "        \"loan_eligibility\": \"No\",\n",
        "        \"segment\": \"Low Value\",\n",
        "        \"campaign_conversion_rate\": 3.4\n",
        "    },\n",
        "     {\n",
        "        \"id\": \"3\",\n",
        "        \"customer_name\": \"Smith\",\n",
        "        \"loan_eligibility\": \"Yes\",\n",
        "        \"segment\": \"Low Value\",\n",
        "        \"campaign_conversion_rate\": 10.4\n",
        "    },\n",
        "]\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728504298589
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install azure.search.documents"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: azure.search.documents in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (11.5.1)\nRequirement already satisfied: azure-core>=1.28.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure.search.documents) (1.31.0)\nRequirement already satisfied: azure-common>=1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure.search.documents) (1.1.28)\nRequirement already satisfied: isodate>=0.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure.search.documents) (0.6.1)\nRequirement already satisfied: typing-extensions>=4.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure.search.documents) (4.12.2)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core>=1.28.0->azure.search.documents) (2.32.3)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core>=1.28.0->azure.search.documents) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure.search.documents) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure.search.documents) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure.search.documents) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure.search.documents) (2024.8.30)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728504389628
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload Data to the Index\n",
        "Once the index is created, you can upload the campaign results data to it. Use the SearchClient to do this."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents import SearchClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "\n",
        "# Create a search client\n",
        "search_client = SearchClient(endpoint=endpoint, index_name=index_name, credential=AzureKeyCredential(api_key))\n",
        "\n",
        "# Upload campaign data (batching is recommended for larger datasets)\n",
        "documents = results  # This should be your list of campaign data dictionaries\n",
        "upload_result = search_client.upload_documents(documents=documents)\n",
        "\n",
        "print(f\"Upload status: {upload_result}\")\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'endpoint' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcredentials\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureKeyCredential\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create a search client\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m search_client \u001b[38;5;241m=\u001b[39m SearchClient(endpoint\u001b[38;5;241m=\u001b[39m\u001b[43mendpoint\u001b[49m, index_name\u001b[38;5;241m=\u001b[39mindex_name, credential\u001b[38;5;241m=\u001b[39mAzureKeyCredential(api_key))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Upload campaign data (batching is recommended for larger datasets)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m documents \u001b[38;5;241m=\u001b[39m results  \u001b[38;5;66;03m# This should be your list of campaign data dictionaries\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'endpoint' is not defined"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728504631110
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Search the index\n",
        "results = search_client.search(query=\"High Value\")\n",
        "\n",
        "for result in results:\n",
        "    print(f\"customer: {result['Customer_name']}, Conversion Rate: {result['campaign_conversion_rate']}%\")\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'search_client' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Search the index\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msearch_client\u001b[49m\u001b[38;5;241m.\u001b[39msearch(query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh Value\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomer_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Conversion Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcampaign_conversion_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'search_client' is not defined"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1728504876329
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}